{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 1,
>>>>>>> 671e7ae497ef89f0b83b88588a6474dd0d21454c
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": null,
>>>>>>> 671e7ae497ef89f0b83b88588a6474dd0d21454c
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering\n",
    "* Hur stor korpus ska vi ha? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nilsjeo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "     och            \n",
      "0    det            \n",
      "1    att            \n",
      "2    i              \n",
      "3    han            \n",
      "4    på             \n",
      "..               ...\n",
      "104    vårt         \n",
      "105    våra         \n",
      "106    ert          \n",
      "107     era         \n",
      "108    vilkas       \n",
      "\n",
      "[109 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#print(stopwords.fileids())\n",
    "\n",
    "#Fick en massa errors när jag försökte ladda ner stopwords, hittade denna lösning online:\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "swe_stop_words = stopwords.words('swedish')\n",
    "print(len(swe_stop_words))\n",
    "\n",
    "# Snowball Swedish Stop Words\n",
    "snowball_sw = pd.read_csv(\"resources/stop_words_swedish_snowball .txt\")\n",
    "print(snowball_sw)\n",
    "\n",
    "# Borrowed from https://github.com/peterdalle/svensktext/tree/master/stoppord\n",
    "def get_stopwords(wordlist = \"standard\"):\n",
    "    if wordlist == \"standard\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord.csv\"\n",
    "    elif wordlist == \"many\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-mycket.csv\"\n",
    "    elif wordlist == \"politics\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-politik.csv\"\n",
    "    else:\n",
    "        raise ValueError(\"Argument 'wordlist' must be 'standard', 'many' or 'politics', not '{}'.\".format(wordlist))\n",
    "    return pd.read_csv(url, header=1, encoding=\"utf-8\")\n",
    "\n",
    "stopwords = get_stopwords()\n",
    "#print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Stop Word Filtering On Example (Original Text) \n",
    "def stop_word_filtering(original_text): \n",
    "    swf_text = None\n",
    "    return swf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer & NER \n",
    "\n",
    "* LEmmatizer verkar ok \n",
    "* NER --> helt klart bristande -- men det kan duga? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(idag, Vietnam, Babij Jar, Katyń, Lidice, Sharpeville, Treblinka)\n",
      "Man\n",
      "man\n",
      "bör\n",
      "böra\n",
      "kalla\n",
      "kalla\n",
      "saker\n",
      "sak\n",
      "och\n",
      "och\n",
      "ting\n",
      "ting\n",
      "vid\n",
      "vid\n",
      "deras\n",
      "de\n",
      "rätta\n",
      "rätt\n",
      "namn\n",
      "namn\n",
      "och\n",
      "och\n",
      "det\n",
      "den\n",
      "som\n",
      "som\n",
      "pågår\n",
      "pågå\n",
      "idag\n",
      "idag\n",
      "i\n",
      "i\n",
      "Vietnam\n",
      "Vietnam\n",
      ",\n",
      ",\n",
      "det\n",
      "den\n",
      "är\n",
      "vara\n",
      "en\n",
      "en\n",
      "form\n",
      "form\n",
      "av\n",
      "av\n",
      "tortyr\n",
      "tortyr\n",
      ".\n",
      ".\n",
      "Det\n",
      "en\n",
      "man\n",
      "man\n",
      "nu\n",
      "nu\n",
      "gör\n",
      "göra\n",
      ",\n",
      ",\n",
      "det\n",
      "den\n",
      "är\n",
      "vara\n",
      "att\n",
      "att\n",
      "plåga\n",
      "plåga\n",
      "människor\n",
      "människa\n",
      ".\n",
      ".\n",
      "Plåga\n",
      "plåga\n",
      "en\n",
      "en\n",
      "nation\n",
      "nation\n",
      "för\n",
      "för\n",
      "att\n",
      "att\n",
      "förödmjuka\n",
      "förödmjuka\n",
      "den\n",
      "den\n",
      ",\n",
      ",\n",
      "tvinga\n",
      "tvinga\n",
      "den\n",
      "den\n",
      "till\n",
      "till\n",
      "underkastelse\n",
      "underkastelse\n",
      "under\n",
      "under\n",
      "maktspråk\n",
      "maktspråk\n",
      ".\n",
      ".\n",
      "Och\n",
      "och\n",
      "därför\n",
      "därför\n",
      "är\n",
      "vara\n",
      "bombningarna\n",
      "bombningarna\n",
      "ett\n",
      "en\n",
      "illdåd\n",
      "illdåd\n",
      ".\n",
      ".\n",
      "Och\n",
      "och\n",
      "av\n",
      "av\n",
      "det\n",
      "den\n",
      "har\n",
      "ha\n",
      "vi\n",
      "vi\n",
      "många\n",
      "många\n",
      "exempel\n",
      "exempel\n",
      "i\n",
      "i\n",
      "den\n",
      "en\n",
      "moderna\n",
      "modern\n",
      "historien\n",
      "historien\n",
      ".\n",
      ".\n",
      "Och\n",
      "och\n",
      "de\n",
      "de\n",
      "är\n",
      "vara\n",
      "i\n",
      "i\n",
      "allmänhet\n",
      "allmänhet\n",
      "förbundna\n",
      "förbundna\n",
      "med\n",
      "med\n",
      "ett\n",
      "en\n",
      "namn\n",
      "namn\n",
      ":\n",
      ":\n",
      "Guernica\n",
      "Guernica\n",
      ",\n",
      ",\n",
      "Oradour\n",
      "Oradour\n",
      ",\n",
      ",\n",
      "Babij\n",
      "Babij\n",
      "Jar\n",
      "Jar\n",
      ",\n",
      ",\n",
      "Katyń\n",
      "Katyń\n",
      ",\n",
      ",\n",
      "Lidice\n",
      "Lidice\n",
      ",\n",
      ",\n",
      "Sharpeville\n",
      "Sharpeville\n",
      ",\n",
      ",\n",
      "Treblinka\n",
      "treblinka\n",
      ".\n",
      ".\n",
      "Där\n",
      "där\n",
      "har\n",
      "ha\n",
      "våldet\n",
      "våld\n",
      "triumferat\n",
      "triumferat\n",
      ".\n",
      ".\n",
      "Men\n",
      "men\n",
      "eftervärldens\n",
      "eftervärlde\n",
      "dom\n",
      "dom\n",
      "har\n",
      "ha\n",
      "fallit\n",
      "falla\n",
      "hård\n",
      "hård\n",
      "över\n",
      "över\n",
      "dem\n",
      "de\n",
      "som\n",
      "som\n",
      "burit\n",
      "burit\n",
      "ansvaret\n",
      "ansvar\n",
      ".\n",
      ".\n",
      "Nu\n",
      "nu\n",
      "fogas\n",
      "foga\n",
      "ett\n",
      "en\n",
      "nytt\n",
      "ny\n",
      "namn\n",
      "namn\n",
      "till\n",
      "till\n",
      "raden\n",
      "rad\n",
      ":\n",
      ":\n",
      "Hanoi\n",
      "Hanoi\n",
      ",\n",
      ",\n",
      "julen\n",
      "jul\n",
      "1972\n",
      "1972\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Spacy NLP Pipeline\n",
    "# spaCy + Lemmy (https://github.com/sorenlind/lemmy) ??? --> Testa om det blir bättre täckning (recall)? \n",
    "import spacy\n",
    "#from spacy.lang.sv.examples import sentences \n",
    "\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "\n",
    "nlp = spacy.load(\"sv_core_news_sm\")\n",
    "\n",
    "doc = nlp(\"Man bör kalla saker och ting vid deras rätta namn och det som pågår idag i Vietnam, det är en form av tortyr. Det man nu gör, det är att plåga människor. Plåga en nation för att förödmjuka den, tvinga den till underkastelse under maktspråk. Och därför är bombningarna ett illdåd. Och av det har vi många exempel i den moderna historien. Och de är i allmänhet förbundna med ett namn: Guernica, Oradour, Babij Jar, Katyń, Lidice, Sharpeville, Treblinka. Där har våldet triumferat. Men eftervärldens dom har fallit hård över dem som burit ansvaret. Nu fogas ett nytt namn till raden: Hanoi, julen 1972.\")\n",
    "#print(doc.text)\n",
    "print(doc.ents) # --> KANSKE ATT DET STORA PAKETET ÄR BÄTTRE\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    #print(token.text, token.pos_, token.dep_)\n",
    "    print(token.lemma_)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1769675692.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def calc_p_r(text_output, )\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "#def calc_p_r(text_output, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "# Stanza https://stanfordnlp.github.io/stanza/installation_usage.html + Språkbanken https://spraakbanken.gu.se/en/resources/stanzalem\n",
    "# https://nlp.johnsnowlabs.com/2020/05/05/lemma_sv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index org text sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 1 --> Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 2 --> Headings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score\n",
    "* Diskutera hur vi kan använda måtten \n",
    "* If similarity is close --> Similar content --> Remove redundance?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER \n",
    "* (nltk lib) --> (Meningar med Named Entities är troligtvis viktigare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER.ipynb#scrollTo=9RgiqfX5XDqb\n",
    "# SPARK NLP \n",
    "# import sparknlp\n",
    "# spark = sparknlp.start(m1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Standardize and combine scores for each sentence\n",
    "* Reassemble according to ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a87a8a1195fdcabb9ca7a50815c6d80bb1ab206e151f4378da93ce8d88425d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
