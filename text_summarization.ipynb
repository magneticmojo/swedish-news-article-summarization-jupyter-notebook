{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports --> TODO fixa ordning \n",
    "# Web scrapping -->  module för att ladda ner artiklar \n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import nltk \n",
    "import ssl\n",
    "import re  # används ej någonstans (tror jag) / björn\n",
    "import regex as rex # \n",
    "\n",
    "\n",
    "# Summarization length of original text\n",
    "percentage = 0.15\n",
    "n_sentences = 3\n",
    "\n",
    "# Fixes some errors, found online at https://github.com/gunthercox/ChatterBot/issues/930#issuecomment-322111087\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lägg till nya artiklar \n",
    "\n",
    "* Hämta komplett url \n",
    "* Lägg till i python cellen under här\n",
    "* Tilldela till variabeln text \n",
    "* Tryck Restart och sen Run All \n",
    "* Filerna hamnar i mappen \"summarizations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\"\n",
    "#text = 'https://www.svt.se/nyheter/utrikes/stall-dina-fragor-om-kriget-till-svt-s-utrikesreportrar'\n",
    "#text = \"https://www.aftonbladet.se/nyheter/a/kE6j0a/uppgifter-viktigt-fynd-i-jakten-pa-mordarna-i-sodertalje\"\n",
    "text = 'https://www.aftonbladet.se/nyheter/a/EQaJRo/blixtbygget-ska-radda-tyskland-i-vinter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(text, language='sv')\n",
    "article.download()\n",
    "article.parse()\n",
    "text = article.text\n",
    "homepage = article.meta_data['al']['ios']['app_name']\n",
    "link = article.url\n",
    "title = article.title\n",
    "\n",
    "# Beroende på vilken hemsida nyheten kommer ifrån kan titeln och texten inehålla delar av sidan man egentligen inte bryr sig om\n",
    "# T.ex. från aftonbladet är titeln med i texten och texten innehåller en mening som: \"publicerad: 30 sep\", man kan ta bort detta men \n",
    "# det blir om vi får tid över.\n",
    "\n",
    "#print('Title:' , article.title, '\\n\\nText: \\n', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Calculate number of sentences to keep\n",
    "\n",
    "### List 1 - sentences\n",
    "* Varje mening separat\n",
    "\n",
    "### Dataframe - scores\n",
    "#### columns are the score of each ranking measure\n",
    "* Baseline\n",
    "* Headings\n",
    "* TF/IDF-score\n",
    "* NER\n",
    "* ~~Class~~ //Om vi har tid för ML\n",
    "\n",
    "### List 2 -> Cleaned for Stop Words \n",
    "* Varje mening separat \n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Sentences List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bygget längst ut på en flera hundra meter lång pir ser inte mycket ut för världen',\n",
       " 'Ett antal breda, rostfärgade rör som förankrats i havsbotten',\n",
       " 'Plattformar ovanpå',\n",
       " 'Men den här terminalen för flytande naturgas ska rädda tyskarna från att slippa frysa – när vintern kommer',\n",
       " 'WILHELMSHAVEN, TYSKLAND Den byggs i rekordfart']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes endlines:\n",
    "from token import NEWLINE\n",
    "\n",
    "org_sentences = text.replace('\\n\\n', '. ')\n",
    "# creates some exceptions from above rule\n",
    "org_sentences = org_sentences.replace('.. ', '. ')\n",
    "org_sentences = org_sentences.replace(':. ', ': ')\n",
    "org_sentences = org_sentences.split('. ')\n",
    "\n",
    "sentences_to_remove = []\n",
    "for i, sentence in enumerate(org_sentences): \n",
    "    if sentence == title: \n",
    "        sentences_to_remove.append(sentence)\n",
    "    if 'publicerad:' in sentence.lower(): \n",
    "        sentences_to_remove.append(sentence)\n",
    "    if 'uppdaterad:' in sentence.lower(): \n",
    "        sentences_to_remove.append(sentence)\n",
    "\n",
    "org_sentences = [sentence for sentence in org_sentences if sentence not in sentences_to_remove]\n",
    "\n",
    "org_sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108 entries, 0 to 107\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Baseline  108 non-null    int64\n",
      " 1   Headings  108 non-null    int64\n",
      " 2   TF        108 non-null    int64\n",
      " 3   NER       108 non-null    int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.5 KB\n"
     ]
    }
   ],
   "source": [
    "index = range(org_sentences.__len__())\n",
    "columns = ['Baseline', 'Headings', 'TF', 'NER']\n",
    "scores = pd.DataFrame(index=index, columns=columns)\n",
    "scores.fillna(0, inplace=True)\n",
    "scores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create spacy doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "# \"lemmatization accuracy 0.95\"\n",
    "# Create spacy nlp object \n",
    "nlp = spacy.load(\"sv_core_news_sm\") # nlp used by lemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bygge länge ut på en flera hundra meter lång pir se inte mycket ut för värld ', 'en antal bred , rostfärga röra som förankra i havsbott ', 'plattformar ovanpå ', 'men en här terminal för flyta naturgas skola rädda tysk från att slippa frysa – när vinter komma ', 'WILHELMSHAVEN , TYSKLAND den bygga i rekordfar ', 'normal ta en sån här anläggning 5–6 år att få klar enligt energibolagen Unipers operative chef Holger kreetz ', 'men genom att snabba på tillståndsprocess och kapa en antal byråkratisk led vara förhoppning att den skola ta lite än tio månad ', 'vi befinna vi i norra Tyskland , vid Yttre hamn i Wilhelmshaven ', 'på ena sida Nordsjön , på en annan en platt landskap med omväxlande industri och lång sandstränd ', 'i slut av december skola en en fartyg som leverera flyta naturgas , så kalla LNG , kunna lägga till vid terminal ', 'en skäl till att den gå så fort vara att en tysk regering ge Uniper i uppdrag att bygga terminal och dessutom drivit igenom en särskild lagstiftning som göra en möjlig ', 'skäl vara att 50 procent av en ga som Tyskland använda för en år sedan komma från ryssland ', 'nu ha president Putin stängt av gasen nästan helt och sprängningarna av Nord stream 1 och 2 ha göra att den inte ens i teori gå att återuppta gasleveranserna i närtid ', 'på en år skola en 70-tal fartyg kunna lossa sig last till en 300 meter långt tankfartyg som då komma att ligga nära pire ', 'Tankern vara omgjord till en lagercentral som en tysk regering hyr för två miljon krona per dag ', 'en nedkyld och kraftig komprimera flyta gasen omvandla sedan till vanlig gas som via pipeline föra ner i en redan existerande tysk gasnät ', '– bara vid en här terminal komma vi att kunna ersätta 20 procent av en ga som Tyskland tidig få från Ryssland , förklara Kreetz ', 'varje fartyg som lägga till innehålla tillräcklig med ga för att förse 50 000 tysk hushåll med sig årsförbrukning ', '– bara vid en här terminal komma vi att kunna ersätta 20 procent av en ga som Tyskland tidig få från Ryssland , säga Unipers operative chef Holger kreetz ', 'denna vara bara en av fyra terminal som hålla på att bygga ', 'en övrig ha dock inte komma lika långt ', 'Gasen kunna komma från hel värld ', 'förbundskansler olaf scholz vara nyligen i Förenade arabemirat och skriva långtidskontrakt för leverans av ga ', 'men LNG-fartyg från Nigeria , USA och Australien komma också att lägga till här ', 'keertz stå med rygg lutad mot reling på en fartyg som uniper hyrt in för att visa media hur bygge gå ', 'vi ligga en 50-tal meter från byggarbetsplatse men få inte gå iland av säkerhetsskäl ', 'den vara svår att begripa att en här bygge kunna betyda så mycket för Tyskland ', 'på håll se vi hur arbetare i skyddsutrustning röra sig på pire bland en rostfärga rör och annan metalldeel ', 'då och då lysa en svetslåga upp ', 'intill ligga flera pråme med stor lyftkrana som dock stå stilla medan vi besöka plats ', 'Vädret vara grå ', 'då och då komma någon regnstänk ', 'men kreetz vara glad att den inte blåse ', '– varje dag med kraftig vind innebära en dags försening av projekten , säga han och blicka orolig mot himl ', 'fram till krig i Ukraina starta ha Tyskland riklig tillgång på billig energi ', 'invasionen av Ukraina ha ge en helt ny situation där Tyskland febrilt leta efter alternativ till en rysk gas ', 'annars riskera land industri att stanna och en tysk välstånd hota ', 'bakom pire där terminal bygga se vi två stor fyrkantig byggnad med skorsten bredvid ', 'från en ena stiga tjock , vit rök mot en grå himl ', 'en av kolkraftverk ha ta ur drift ', 'en två ha få förlänga livstid för att hjälpa Tyskland att producera nödvändig el ', 'egentligen vara mål för Tyskland att fasa ut all kolkraft så snart som möjlig för att minska land koldioxidutsläpp ', 'på sikt vilja man även göra sig av med naturgas som även en bidra till en global uppvärmning ', 'jag fråga Holger kreetz hur den kännas att tvinga återstarta kolkraft och bygga en terminal för mycket naturgas i ställe för lite ', 'han titta upp och skjuta fram haka ', '– frustrerande ', 'den kännas frustrerande ', 'krig göra att man måste fatta beslut man inte vilja ', 'klimathot vara den stor långsiktig hot mot nästa generation som vi måste lösa ', 'men i en situation vi vara i nu måste vi också se till att tysk inte behöva frysa i sig hem i vinter och att företag få en energi som behöva för att driva sig produktion vidare ', 'trots att terminal vara så viktig för Tyskland protestera miljöaktivister vid pire för två månad sedan ', 'just för att de anse att leverans av LNG göra Tyskland fortsätta beroende av fossil bränsle i ställe för att satsa på förnybar ', 'runt 300 klimataktivist protestera i Wilhelmshaven ', '– jag ha ingen problem med de som utnyttja sig rätt att demonstrera fredlig , säga Keertz ', 'men en del av de vara våldsamma och slå sönder utrustning och attackera vi personal ', 'den vara inte acceptabel ', 'klimataspekt vara extra känslig eftersom miljöparti vara en av tre partie som sitta i regering ', 'men ekonomiminister Robert Habeck från en grön ha säga att klimataspekt i en här fall få stå åt sida för en viktig uppgift att förhindra president Putin att fortsätta utpressa Tyskland med sig gasvap ', 'Tanken vara också att terminal om någon år skola kunna omvandla så att den kunna ta emot miljövänlig vätga istället ', 'Kritikerna frukta dock att Tyskland med terminalbygge binda sig alltför hård vid naturgas ', 'oliver powalla från miljöorganisation Bund vara man av de ', '– vi tycka den vara okej att bygga LNG-terminalerna för att lösa en akut energikris men den böra sätta en stoppdatum för hur länge import av LNG få pågå , mena han ', 'powalla ha cykla till vi möte i central Berlin och hålla cykelhjälm i ena hand under intervjun ', '– Tyskland böra i framtid satsa på grön vätga i ställe för en fossil naturgas ', 'men en övergång komma inte att ske så länge den inte finnas en tryck på energibolag att överge naturgas ', 'bund-representant tycka kanske en aning förvånande också att den vara okej att en antal kolkraftverk återstarta trots en öka koldioxidutsläpp den innebära ', '– vi måste göra den för att få fram tillräcklig med el , medge han motvillig ', 'om den handla om två eller tre vintr vara den okej som en nödlösning men vi backa inte på krav att kol måste fasa ut till 2030 ', 'kärnkraft vägra dock Oliver powalla att acceptera trots att regering där en grön ingå ge klarteck till att två reaktor skola köra vidare under vinter ', '– jag tycka den vara fel ', 'kärnkraft tillför så lite extra energi att den vara onödig att ta en risk som en fortsätta drift innebära ', 'titta på vad som hä med Nord stream ', 'se hur nära vi vara en kärnkraftskatastrof i Zaporizjzja i Ukraina ', 'i ställe se han energieffektivisering och sparad som en enskild viktig åtgärd för att Tyskland skola klara sig igenom vinter ', 'tyvärr peka verklighet i rak motsatt riktning ', 'Tyska privatperson vara duktig på att spara på el och ga i början av sommar ', 'men både i augusti och september ha sparand sjunka rejält ', '– folk ha rentav öka sig konsumtion på grund av en ovanlig kall september , konstatera Oliver powalla besvike ', 'fortsätter den så lära vi inte klara vi utan el-avbrott i vinter ', '', '” Måste vara vaksam . ” efter en förmoda terrorattackerna mot Nord stream 1 och 2 finnas en oro hos energibolag Uniper ', 'Åter till Wilhelmshaven ', 'Precis innan vi lämna kaj för en kort båtresa ut till pire ligga en stor krigsfartyg ute på redd ', 'jag undra om den ligga där för att avskräcka från attack och skydda anläggning ', '– jag veta faktisk inte , svara Kreetz ', 'den ligga en stor flottba i Wilhelmshaven ', 'kanske passera den bara förbi på väg mot bas ', 'men att säkerhet kring land energianläggning bli hög priorit råda den ingen tvekan om ', '– en förmoda terrorattackerna mot Nord stream 1 och 2 visa hur viktig den vara att vi säkra vi vital infrastruktur ', 'inte bara gasledningarna utan också vi kraftverk ', 'vi måste skydda vi bra ', 'vara du rädd för en attack mot en här terminal ? ', '– rädsla vara ingen bra känsla att förlita sig på ', 'men vi vara försiktig och vaksamma ', 'vi måste komma ihåg att den pågå en krig i Europa och att terrorattack kunna inträffa ', 'i nuläg vara en tysk gaslagren fyllda till omkring 90 procent ', 'vilken böra göra att land klara sig igenom vinter om den inte bli alltför sträng ', 'men osäkerheten kring tillgång på ga göra att pris ändå vara fortsätta hög ', 'hur skola den exempelvis gå att fylla lagr inför nästa vinter ? ', 'på väg tillbaka passera vi rad av grävmaskin som bygga en stor dike i en grön , platta landskap ', 'den vara gasledning som skola ta LNG-gase fram till där den gå att ansluta till en tysk gasnät ', 'en sträcka på en antal mil ', 'syn påminna jag om bild som komma ut från Wuhan i Kina när pandemi bröt ut ', 'Bilder där en mylla av grävskopa lägga grund för en omöjlig ', 'att bygga två helt ny sjukhus på en vecka ', 'nu vara Tyskland i samma situation ', 'de måste lycka med en omöjlig ', 'Aftonbladets fotograf Jerker Ivarsson och report Wolfgang Hansson på plats i Wilhelmshaven , Tyskland . ']\n"
     ]
    }
   ],
   "source": [
    "# den --> det \n",
    "# noterar detta att det är en dålig lemmatiserare --> språkbanken stanza / lemmy / kth...  \n",
    "\n",
    "def lemmatizer(list_of_strings):\n",
    "    lemmatized_sentences = []\n",
    "    lemmatized_sentence = ''\n",
    "    for i in range(len(list_of_strings)): \n",
    "        sentence_to_lemmatize = nlp(list_of_strings[i])\n",
    "        for token in sentence_to_lemmatize:\n",
    "            lemma = token.lemma_\n",
    "            lemmatized_sentence += lemma + ' '  \n",
    "        \n",
    "        lemmatized_sentences.append(lemmatized_sentence)\n",
    "        lemmatized_sentence = '' \n",
    "\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# Created Lemmatized DS\n",
    "lemmatized_org_sentences = lemmatizer(org_sentences)\n",
    "print(lemmatized_org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LNG', 'Wilhelmshaven', 'Nord', 'USA', 'Keertz', 'Hansson', 'Wolfgang', 'Oliver', 'Kina', 'Holger', 'Rädsla', 'Australien', 'Putin', 'Ryssland', 'Berlin', 'Nigeria', 'Ukraina', 'Ivarsson', 'Jerker', 'WILHELMSHAVEN', 'Zaporizjzja', 'TYSKLAND', 'Bund', 'Wuhan', 'Unipers', 'Tyskland', 'Europa', 'Nordsjön'}\n"
     ]
    }
   ],
   "source": [
    "# För bättre täckning på NER \n",
    "def proper_nouns(list_of_strings):\n",
    "    proper_nouns = set()\n",
    "    for i in range(len(list_of_strings)): \n",
    "        sentence_to_pos = nlp(list_of_strings[i])\n",
    "        for token in sentence_to_pos: \n",
    "            token_str = token.text\n",
    "            if token.pos_ == \"PROPN\" and len(token_str) > 1:\n",
    "                proper_nouns.add(token_str.strip())\n",
    "    return proper_nouns\n",
    "\n",
    "print(proper_nouns(org_sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_recognition(list_of_strings):\n",
    "    doc = nlp(' '.join(list_of_strings))\n",
    "    # Convert tuple[Span] to str\n",
    "    named_entities = doc.ents.__str__()\n",
    "    # Remove string parenthesis \n",
    "    named_entities = named_entities[1:len(named_entities) - 1]\n",
    "    # Create list of strings\n",
    "    named_entities = named_entities.split(',')\n",
    "    \n",
    "    named_entities_set = set()\n",
    "    for entity in named_entities: \n",
    "        named_entities_set.add(entity.strip())\n",
    "    return named_entities_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def get_swe_stop_words(): \n",
    "    swe_stop_words = set(stopwords.words('swedish'))\n",
    "    # Not stop word cleaning \n",
    "    swe_stop_words.update([',', '\"', ':', '-', '–', '”'])\n",
    "    return swe_stop_words\n",
    "\n",
    "def stop_word_filtering(list_of_strings):\n",
    "    word_tokens = word_tokenize(' '.join(list_of_strings))\n",
    "    filtered_sentence_into_singletons = [w for w in word_tokens if not w.lower() in get_swe_stop_words()]\n",
    "    return filtered_sentence_into_singletons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_distribution(list): \n",
    "    fdist = FreqDist(word.lower() for word in word_tokenize(' '.join(list)))\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = stop_word_filtering(lemmatized_org_sentences) \n",
    "fdist = frequency_distribution(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.036045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline  Headings     TF    NER\n",
       "count  108.000000     108.0  108.0  108.0\n",
       "mean     0.048740       0.0    0.0    0.0\n",
       "std      0.113531       0.0    0.0    0.0\n",
       "min      0.009259       0.0    0.0    0.0\n",
       "25%      0.012308       0.0    0.0    0.0\n",
       "50%      0.018350       0.0    0.0    0.0\n",
       "75%      0.036045       0.0    0.0    0.0\n",
       "max      1.000000       0.0    0.0    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 1 --> Baseline\n",
    "for i, score in enumerate(scores['Baseline']) :\n",
    "    scores['Baseline'][i] = 1/((i+1))\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048740</td>\n",
       "      <td>0.87963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113531</td>\n",
       "      <td>0.92441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018350</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.036045</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline   Headings     TF    NER\n",
       "count  108.000000  108.00000  108.0  108.0\n",
       "mean     0.048740    0.87963    0.0    0.0\n",
       "std      0.113531    0.92441    0.0    0.0\n",
       "min      0.009259    0.00000    0.0    0.0\n",
       "25%      0.012308    0.00000    0.0    0.0\n",
       "50%      0.018350    1.00000    0.0    0.0\n",
       "75%      0.036045    1.00000    0.0    0.0\n",
       "max      1.000000    4.00000    0.0    0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 2 --> Headings\n",
    "# Sets all 'Headings' scores to 0, mostly for testing so i can run this multiple times, \n",
    "# but also to make sure nothing weird has happened earlier in the code.\n",
    "scores['Headings'] = 0\n",
    "for i, sentence in enumerate(org_sentences): # Lemmatizerad? \n",
    "    for word in article.title.split(' '):\n",
    "        if word in sentence:\n",
    "            scores.at[i, 'Headings'] += 1\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sverigedemokraterna få ordförandepost i riksdag justitie och utrikesutskott \n",
    "[' få ', 'ordförandepost ', 'riksdag ', 'utrikesutskott ']\n",
    "\n",
    "* bara ord i lemma \n",
    "* ord i lemma med efter letters\n",
    "* ord i lemma med före letters --> x\n",
    "* före + lemma + efter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048740</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113531</td>\n",
       "      <td>1.102092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.036045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline    Headings     TF    NER\n",
       "count  108.000000  108.000000  108.0  108.0\n",
       "mean     0.048740    0.981481    0.0    0.0\n",
       "std      0.113531    1.102092    0.0    0.0\n",
       "min      0.009259    0.000000    0.0    0.0\n",
       "25%      0.012308    0.000000    0.0    0.0\n",
       "50%      0.018350    1.000000    0.0    0.0\n",
       "75%      0.036045    1.000000    0.0    0.0\n",
       "max      1.000000    5.000000    0.0    0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_title = stop_word_filtering(lemmatizer(title.split(' ')))\n",
    "p = rex.compile(r\"\\b\\S*\\L<words>\\S*\\b | \\b\\L<words>\\b | \\b\\L<words>\\S*\\b\", re.IGNORECASE, words=preprocessed_title)\n",
    "p.findall\n",
    "\n",
    "for i, sentence in enumerate(lemmatized_org_sentences):    \n",
    "    #print(sentence)\n",
    "    matches = p.findall(sentence)\n",
    "    #print(matches)\n",
    "    scores.at[i, \"Headings\"] = len(matches)\n",
    "\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TERM FREQUENCY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "#Term Frequency\n",
    "def termfreq(sentence, word):\n",
    "    N = len(sentence)\n",
    "    occurance = len([token for token in sentence if token == word])\n",
    "    return occurance/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "#Inverse Document Frequency\n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = fdist.get(word) + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(len(lemmatized_org_sentences)/word_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "# TF*IDF-score \n",
    "def tf_idf(sentence):\n",
    "    score = 0\n",
    "    #tf_idf_vec = np.zeros((len(filtered_words),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "         \n",
    "        score += tf*idf\n",
    "        #tf_idf_vec[index_dict[word]] = value \n",
    "    return score\n",
    "\n",
    "for i, sentence in enumerate(lemmatized_org_sentences):\n",
    "    scores.at[i, 'TF'] = tf_idf(sentence)\n",
    "\n",
    "#scores.describe()\n",
    "#scores['TF'].idxmax()\n",
    "#scores.loc[scores['TF'] == scores['TF'].median()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LNG', 'USA', 'Keertz', 'Wilhelmshaven', 'Nord', 'Wolfgang Hansson', 'nyligen', 'Hansson', 'Wolfgang', 'Oliver', 'Nord Stream 1', 'Kina', 'Holger', 'Nu', 'för ett år sedan', 'i framtiden', 'Rädsla', 'Australien', 'Putin', 'Habeck', 'Ryssland', 'Robert', 'Nigeria', 'Kreetz', 'Ukraina', 'Berlin', 'Ivarsson', 'Jerker', 'WILHELMSHAVEN', 'Zaporizjzja', 'TYSKLAND', 'Uniper', 'Bund', 'Wuhan', 'Unipers', 'Olaf', 'Tyskland', 'Yttre', 'Plattformar', 'Oliver Powalla', 'På ett år', 'Europa', 'Jerker Ivarsson', 'De gröna', 'Holger Kreetz', 'Nordsjön'}\n"
     ]
    }
   ],
   "source": [
    "scores['NER'] = 0\n",
    "named_entities = named_entity_recognition(org_sentences)\n",
    "proper_nouns = proper_nouns(org_sentences)\n",
    "ner_unique = named_entities.union(proper_nouns)\n",
    "print(ner_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>30.829098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>22.729619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>8.624979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>36.057237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>11.854758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Baseline  Headings         TF  NER\n",
       "0  1.000000         0  30.829098    0\n",
       "1  0.500000         1  22.729619    0\n",
       "2  0.333333         0   8.624979    1\n",
       "3  0.250000         2  36.057237    0\n",
       "4  0.200000         1  11.854758    2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = rex.compile(r\"\\L<words>\", words=ner_unique)\n",
    "\n",
    "for i, sentence in enumerate(org_sentences):\n",
    "    matches = p.findall(sentence)\n",
    "    scores.at[i, \"NER\"] = len(matches)\n",
    "\n",
    "scores.describe()\n",
    "scores.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.626894</td>\n",
       "      <td>-2.236785</td>\n",
       "      <td>0.010758</td>\n",
       "      <td>-0.722652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.989960</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>-0.162605</td>\n",
       "      <td>-0.722652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.777648</td>\n",
       "      <td>-2.236785</td>\n",
       "      <td>-0.464503</td>\n",
       "      <td>0.195541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.671493</td>\n",
       "      <td>2.321192</td>\n",
       "      <td>0.122663</td>\n",
       "      <td>-0.722652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.007799</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>-0.395372</td>\n",
       "      <td>1.113735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-0.519341</td>\n",
       "      <td>-2.236785</td>\n",
       "      <td>-0.188114</td>\n",
       "      <td>-0.722652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.520557</td>\n",
       "      <td>-2.236785</td>\n",
       "      <td>-0.276878</td>\n",
       "      <td>-0.722652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.521749</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>-0.308375</td>\n",
       "      <td>1.113735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.522920</td>\n",
       "      <td>-2.236785</td>\n",
       "      <td>-0.375187</td>\n",
       "      <td>-0.722652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-0.524068</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>2.950121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Baseline  Headings        TF       NER\n",
       "0    12.626894 -2.236785  0.010758 -0.722652\n",
       "1     5.989960  0.042203 -0.162605 -0.722652\n",
       "2     3.777648 -2.236785 -0.464503  0.195541\n",
       "3     2.671493  2.321192  0.122663 -0.722652\n",
       "4     2.007799  0.042203 -0.395372  1.113735\n",
       "..         ...       ...       ...       ...\n",
       "103  -0.519341 -2.236785 -0.188114 -0.722652\n",
       "104  -0.520557 -2.236785 -0.276878 -0.722652\n",
       "105  -0.521749  0.042203 -0.308375  1.113735\n",
       "106  -0.522920 -2.236785 -0.375187 -0.722652\n",
       "107  -0.524068  0.042203  0.000145  2.950121\n",
       "\n",
       "[108 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize\n",
    "scores_standardized = StandardScaler.fit_transform(self=StandardScaler(), X=scores)\n",
    "scores_standardized = pd.DataFrame(scores_standardized, columns=columns)\n",
    "scores_standardized['Baseline'] *= 1.5\n",
    "scores_standardized['Headings'] *= 2.5\n",
    "scores_standardized['TF'] *= 0.3\n",
    "scores_standardized\n",
    "\n",
    "# ÄNDRA COL NAME TF col --> TF*IDF TODO \n",
    "# COUNTER WEIGHT: \n",
    "# IF -->  \n",
    "# Baseline score low (e.g. below median)\n",
    "# && term_frequency high (note: not TF*IDF) (e.g. above upper quartile)\n",
    "# && NER high (e.g. above upper quartile)\n",
    "# THEN: \n",
    "# add_counterweight(sentence, counter_weight) \n",
    "# counter_weight:  \n",
    "# final rankposition = i -->  ∑ -1 (-1 may be too big weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Summarization Length (number of sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarization:  16 \n",
      "original:  108\n"
     ]
    }
   ],
   "source": [
    "num_of_org_sentences = len(org_sentences)\n",
    "summarization_num_sentences = round(num_of_org_sentences * percentage)\n",
    "\n",
    "print(\"summarization: \", summarization_num_sentences, \"\\noriginal: \", num_of_org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine\n",
    "* Combine the scores into one overall score\n",
    "* add weight and/or ML if time allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57  12   0 100  15  18  35   1  65  16   3  59   9  51  34   6]\n",
      "Bygget längst ut på en flera hundra meter lång pir ser inte mycket ut för världen\n"
     ]
    }
   ],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  \n",
    "\n",
    "#final_score = scores_standardized.drop('TF', axis=1).sum(axis=1)\n",
    "final_score = scores_standardized.sum(axis=1)\n",
    "best_sentences = final_score.nlargest(summarization_num_sentences, keep='all').index.values\n",
    "print(best_sentences)\n",
    "\n",
    "print(org_sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity heurstic \n",
    "# Rubrik --> Hur mycket lika --> Ta bort redundans \n",
    "# 5 fem väldigt lika --> heuristik välja bort något av det     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Reassemble according to overall score ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage:\n",
      "\n",
      "Putin stängde av gasen – då tog Tyskland ett blixtbeslut \n",
      "\n",
      "Men ekonomiminister Robert Habeck från De gröna har sagt att klimataspekten i det här fallet får stå åt sidan för den viktigare uppgiften att förhindra president Putin att fortsätta utpressa Tyskland med sitt gasvapen\n",
      "Nu har president Putin stängt av gasen nästan helt och sprängningarna av Nord Stream 1 och 2 har gjort att det inte ens i teorin går att återuppta gasleveranserna i närtid\n",
      "Bygget längst ut på en flera hundra meter lång pir ser inte mycket ut för världen\n",
      "Det är gasledningen som ska ta LNG-gasen fram till där det går att ansluta till det tyska gasnätet\n",
      "Den nedkylda och kraftigt komprimerade flytande gasen omvandlas sedan till vanlig gas som via pipelines förs ner i det redan existerande tyska gasnätet\n",
      "– Bara vid den här terminalen kommer vi att kunna ersätta 20 procent av den gas som Tyskland tidigare fått från Ryssland, säger Unipers operative chef Holger Kreetz\n",
      "Invasionen av Ukraina har gett en helt ny situation där Tyskland febrilt letar efter alternativ till den ryska gasen\n",
      "Ett antal breda, rostfärgade rör som förankrats i havsbotten\n",
      "Bund-representanten tycker kanske en aning förvånande också att det är okej att ett antal kolkraftverk återstartas trots de ökade koldioxidutsläpp det innebär\n",
      "– Bara vid den här terminalen kommer vi att kunna ersätta 20 procent av den gas som Tyskland tidigare fått från Ryssland, förklarar Kreetz\n",
      "Men den här terminalen för flytande naturgas ska rädda tyskarna från att slippa frysa – när vintern kommer\n",
      "Kritikerna fruktar dock att Tyskland med terminalbygget binder sig alltför hårt vid naturgasen\n",
      "I slutet av december ska de första fartygen som levererar flytande naturgas, så kallad LNG, kunna lägga till vid terminalen\n",
      "Just för att de anser att leveranserna av LNG gör Tyskland fortsatt beroende av fossila bränslen i stället för att satsa på förnybara\n",
      "Fram till kriget i Ukraina startade hade Tyskland riklig tillgång på billig energi\n",
      "Men genom att snabba på tillståndsprocessen och kapa ett antal byråkratiska led är förhoppningen att det ska ta mindre än tio månader\n",
      "\n",
      "\n",
      "\n",
      "N sentences:\n",
      "\n",
      "Men ekonomiminister Robert Habeck från De gröna har sagt att klimataspekten i det här fallet får stå åt sidan för den viktigare uppgiften att förhindra president Putin att fortsätta utpressa Tyskland med sitt gasvapen\n",
      "Nu har president Putin stängt av gasen nästan helt och sprängningarna av Nord Stream 1 och 2 har gjort att det inte ens i teorin går att återuppta gasleveranserna i närtid\n",
      "Bygget längst ut på en flera hundra meter lång pir ser inte mycket ut för världen\n"
     ]
    }
   ],
   "source": [
    "# Percentage length of original text --> summarization \n",
    "print(\"Percentage:\\n\")\n",
    "print(title, \"\\n\")\n",
    "for i in best_sentences: \n",
    "    print(org_sentences[i])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# N sentences \n",
    "print(\"N sentences:\\n\")\n",
    "for i in best_sentences[0:n_sentences]: \n",
    "    print(org_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Newspaper3k: \n",
      " Men genom att snabba på tillståndsprocessen och kapa ett antal byråkratiska led är förhoppningen att det ska ta mindre än tio månader.\n",
      "I stället ser han energieffektivisering och sparade som de enskilt viktigaste åtgärderna för att Tyskland ska klara sig igenom vintern.\n",
      "Precis innan vi lämnar kajen för den korta båtresan ut till piren ligger ett stort krigsfartyg ute på redden.\n",
      "Hur ska det exempelvis gå att fylla lagren inför nästa vinter?\n",
      "Det är gasledningen som ska ta LNG-gasen fram till där det går att ansluta till det tyska gasnätet.\n"
     ]
    }
   ],
   "source": [
    "# Newspaper Summarization\n",
    "article.nlp()\n",
    "print(\"\\nNewspaper3k: \\n\", article.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization = link + '\\n\\n' + 'Title: ' + '\\n' + title + '\\n\\n' + 'Summarization:' + '\\n'\n",
    "for sentence in best_sentences: \n",
    "    summarization += org_sentences[sentence] + '\\n'\n",
    "summarization += '\\n\\n' + 'Newspaper3k:' + '\\n' + 'Title: ' + '\\n' + title + \"\\n\\n\" + article.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# FILEPATH = f'./summarizations/{homepage}/'\n",
    "# filename = f\"{FILEPATH}{title}.txt\"\n",
    "# os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "# with open(filename, 'w') as f:\n",
    "#      f.write(summarization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f84c718007c4e73e911614ffefbbc4d70113307eb785d27a429d66e7eb72440b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
