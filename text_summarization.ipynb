{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import ssl\n",
    "\n",
    "# Fixes some errors, found online at https://github.com/gunthercox/ChatterBot/issues/930#issuecomment-322111087\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrapping -->  module för att ladda ner artiklar \n",
    "from newspaper import Article\n",
    "text = \"https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\"\n",
    "article = Article(text, language='sv')\n",
    "article.download()\n",
    "article.parse()\n",
    "#article.nlp()\n",
    "#article.summary\n",
    "\n",
    "text = article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### List 1 - sentences\n",
    "* Varje mening separat\n",
    "\n",
    "### Dataframe - scores\n",
    "#### columns are the score of each ranking measure\n",
    "* Baseline\n",
    "* Headings\n",
    "* TF/IDF-score\n",
    "* NER\n",
    "* ~~Class~~ //Om vi har tid för ML\n",
    "\n",
    "### Array 2 -> Cleaned for Stop Words \n",
    "* Varje mening separat \n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SD får tunga poster i utskotten',\n",
       " 'Publicerad: Mindre än 3 tim sedan Uppdaterad: Mindre än 40 min sedan',\n",
       " 'Sverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott',\n",
       " 'Nu går ledarna för vänsterblocket till hård attack',\n",
       " '– Det är skrämmande, ganska chockartat, säger Socialdemokraternas gruppledare Lena Hallengren till Aftonbladet',\n",
       " 'Sverigedemokraterna , Moderaterna, Kristdemokraterna och Liberalerna har delat upp posterna i utskotten och EU-nämnden',\n",
       " 'Där tar Sverigedemokraterna flera viktiga poster',\n",
       " 'Bland annat tilldelas partiet ordförandeposten i arbetsmarknadsutskottet, näringsutskottet, justitieutskottet samt utrikesutskottet, enligt ett pressmeddelande',\n",
       " 'De erhåller även posten som vice ordförande i civilutskottet, trafikutskottet, försvarsutskottet samt skatteutskottet',\n",
       " '– Det som överraskade mig mest, men som jag kan se varför de vill ha, är ordförandeposten i utrikesutskottet']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes endlines:\n",
    "from token import NEWLINE\n",
    "\n",
    "\n",
    "org_sentences = text.replace('\\n\\n', '. ')\n",
    "# creates some exceptions from above rule\n",
    "org_sentences = org_sentences.replace('.. ', '. ')\n",
    "org_sentences = org_sentences.replace(':. ', ': ')\n",
    "org_sentences = org_sentences.split('. ')\n",
    "org_sentences[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34 entries, 0 to 33\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Baseline  34 non-null     int64\n",
      " 1   Headings  34 non-null     int64\n",
      " 2   TF/IDF    34 non-null     int64\n",
      " 3   NER       34 non-null     int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 1.2 KB\n"
     ]
    }
   ],
   "source": [
    "index = range(org_sentences.__len__())\n",
    "columns = ['Baseline', 'Headings', 'TF/IDF', 'NER']\n",
    "scores = pd.DataFrame(index=index, columns=columns)\n",
    "scores.fillna(0, inplace=True)\n",
    "scores.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering\n",
    "* Hur stor korpus ska vi ha? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "swe_stop_words = stopwords.words('swedish')\n",
    "print(len(swe_stop_words))\n",
    "\n",
    "# Snowball Swedish Stop Words\n",
    "snowball_sw = pd.read_csv(\"resources/stop_words_swedish_snowball .txt\")\n",
    "# print(snowball_sw)\n",
    "\n",
    "# Borrowed from https://github.com/peterdalle/svensktext/tree/master/stoppord\n",
    "def get_stopwords(wordlist = \"standard\"):\n",
    "    if wordlist == \"standard\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord.csv\"\n",
    "    elif wordlist == \"many\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-mycket.csv\"\n",
    "    elif wordlist == \"politics\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-politik.csv\"\n",
    "    else:\n",
    "        raise ValueError(\"Argument 'wordlist' must be 'standard', 'many' or 'politics', not '{}'.\".format(wordlist))\n",
    "    return pd.read_csv(url, header=1, encoding=\"utf-8\")\n",
    "\n",
    "stopwords = get_stopwords()\n",
    "# print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Stop Word Filtering On Example (Original Text) \n",
    "def stop_word_filtering(original_text): \n",
    "    swf_text = None\n",
    "    return swf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer & NER \n",
    "\n",
    "* LEmmatizer verkar ok \n",
    "* NER --> helt klart bristande -- men det kan duga? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE DUPLICATE ENTITIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\n",
      "https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskott\n"
     ]
    }
   ],
   "source": [
    "# Spacy NLP Pipeline\n",
    "# spaCy + Lemmy (https://github.com/sorenlind/lemmy) ??? --> Testa om det blir bättre täckning (recall)? \n",
    "import spacy\n",
    "#from spacy.lang.sv.examples import sentences \n",
    "\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "\n",
    "nlp = spacy.load(\"sv_core_news_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "#print(doc.text)\n",
    "print(doc.ents) # --> KANSKE ATT DET STORA PAKETET ÄR BÄTTRE\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    #print(token.text, token.pos_, token.dep_)\n",
    "    print(token.lemma_)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision & Recall \n",
    "def calc_p_r(text_output): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "# Stanza https://stanfordnlp.github.io/stanza/installation_usage.html + Språkbanken https://spraakbanken.gu.se/en/resources/stanzalem\n",
    "# https://nlp.johnsnowlabs.com/2020/05/05/lemma_sv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index org text sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 1 --> Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 2 --> Headings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score\n",
    "* Diskutera hur vi kan använda måtten \n",
    "* If similarity is close --> Similar content --> Remove redundance?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER \n",
    "* (nltk lib) --> (Meningar med Named Entities är troligtvis viktigare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER.ipynb#scrollTo=9RgiqfX5XDqb\n",
    "# SPARK NLP \n",
    "import sparknlp\n",
    "spark = sparknlp.start(m1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Standardize\n",
    "* standardize between all scores bwetween 0-1\n",
    "### Combine\n",
    "* Combine the scores into one overall score\n",
    "* add weight and/or ML if time allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Reassemble according to overall score ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a87a8a1195fdcabb9ca7a50815c6d80bb1ab206e151f4378da93ce8d88425d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
