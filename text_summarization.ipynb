{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import nltk \n",
    "import ssl\n",
    "\n",
    "# Fixes some errors, found online at https://github.com/gunthercox/ChatterBot/issues/930#issuecomment-322111087\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrapping -->  module för att ladda ner artiklar \n",
    "from newspaper import Article\n",
    "text = \"https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\"\n",
    "article = Article(text, language='sv')\n",
    "article.download()\n",
    "article.parse()\n",
    "#article.nlp()\n",
    "#article.summary\n",
    "\n",
    "text = article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### DATAFRAM \n",
    "* cols \n",
    "* Varje mening separat  \n",
=======
    "## Overview\n",
    "### List 1 - sentences\n",
    "* Varje mening separat\n",
>>>>>>> bba52313580c3168cfcada6c59d927edf5c2ccb7
    "\n",
    "### Dataframe - scores\n",
    "#### columns are the score of each ranking measure\n",
    "* Baseline\n",
    "* Headings\n",
    "* TF/IDF-score\n",
    "* NER\n",
    "* ~~Class~~ //Om vi har tid för ML\n",
    "\n",
    "### List 2 -> Cleaned for Stop Words \n",
    "* Varje mening separat \n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SD får tunga poster i utskotten',\n",
       " 'Publicerad: I dag 12.09 Uppdaterad: Mindre än 3 tim sedan',\n",
       " 'Sverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott',\n",
       " 'Nu går ledarna för vänsterblocket till hård attack',\n",
       " '– Det är skrämmande, ganska chockartat, säger Socialdemokraternas gruppledare Lena Hallengren till Aftonbladet',\n",
       " 'Sverigedemokraterna , Moderaterna, Kristdemokraterna och Liberalerna har delat upp posterna i utskotten och EU-nämnden',\n",
       " 'Där tar Sverigedemokraterna flera viktiga poster',\n",
       " 'Bland annat tilldelas partiet ordförandeposten i arbetsmarknadsutskottet, näringsutskottet, justitieutskottet samt utrikesutskottet, enligt ett pressmeddelande',\n",
       " 'De erhåller även posten som vice ordförande i civilutskottet, trafikutskottet, försvarsutskottet samt skatteutskottet',\n",
       " '– Det som överraskade mig mest, men som jag kan se varför de vill ha, är ordförandeposten i utrikesutskottet']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes endlines:\n",
    "from token import NEWLINE\n",
    "\n",
    "\n",
    "org_sentences = text.replace('\\n\\n', '. ')\n",
    "# creates some exceptions from above rule\n",
    "org_sentences = org_sentences.replace('.. ', '. ')\n",
    "org_sentences = org_sentences.replace(':. ', ': ')\n",
    "org_sentences = org_sentences.split('. ')\n",
    "org_sentences[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34 entries, 0 to 33\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Baseline  34 non-null     int64\n",
      " 1   Headings  34 non-null     int64\n",
      " 2   TF/IDF    34 non-null     int64\n",
      " 3   NER       34 non-null     int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 1.2 KB\n"
     ]
    }
   ],
   "source": [
    "index = range(org_sentences.__len__())\n",
    "columns = ['Baseline', 'Headings', 'TF/IDF', 'NER']\n",
    "scores = pd.DataFrame(index=index, columns=columns)\n",
    "scores.fillna(0, inplace=True)\n",
    "scores.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering\n",
    "* Hur stor korpus ska vi ha? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "swe_stop_words = stopwords.words('swedish')\n",
    "print(len(swe_stop_words))\n",
    "\n",
    "# Snowball Swedish Stop Words\n",
    "snowball_sw = pd.read_csv(\"resources/stop_words_swedish_snowball .txt\")\n",
    "# print(snowball_sw)\n",
    "\n",
    "# Borrowed from https://github.com/peterdalle/svensktext/tree/master/stoppord\n",
    "def get_stopwords(wordlist = \"standard\"):\n",
    "    if wordlist == \"standard\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord.csv\"\n",
    "    elif wordlist == \"many\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-mycket.csv\"\n",
    "    elif wordlist == \"politics\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-politik.csv\"\n",
    "    else:\n",
    "        raise ValueError(\"Argument 'wordlist' must be 'standard', 'many' or 'politics', not '{}'.\".format(wordlist))\n",
    "    return pd.read_csv(url, header=1, encoding=\"utf-8\")\n",
    "\n",
    "stopwords = get_stopwords()\n",
    "# print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Stop Word Filtering On Example (Original Text) \n",
    "def stop_word_filtering(original_text): \n",
    "    swf_text = None\n",
    "    return swf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer & NER \n",
    "\n",
    "* LEmmatizer verkar ok \n",
    "* NER --> helt klart bristande -- men det kan duga? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE DUPLICATE ENTITIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Socialdemokraternas, Lena, Aftonbladet, Moderaterna, KD, Aftonbladets My Rohwedder, Aftonbladet, Sveriges, Moderaterna, Ulf Kristerssons, Lena Hallengren, Sverige, Skämmer, Sverige, Märta, Twitter:\n",
      "\n",
      ", Putin, Biden, Sverige, Twitter.\n",
      "\n",
      ", Ali, Esbati, Martin Kinnunen, Markus Wiechels, Syrien, Marcus Wiechel, Martin Kinnunen, UD:s, Syrien, Annie, KD, Sverige, Nato, Sveriges, Jakob Hallgren)\n"
     ]
    }
   ],
   "source": [
    "# Spacy NLP Pipeline\n",
    "# spaCy + Lemmy (https://github.com/sorenlind/lemmy) ??? --> Testa om det blir bättre täckning (recall)? \n",
    "import spacy\n",
    "#from spacy.lang.sv.examples import sentences \n",
    "\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "\n",
    "nlp = spacy.load(\"sv_core_news_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "#print(doc.text)\n",
    "print(doc.ents) # --> KANSKE ATT DET STORA PAKETET ÄR BÄTTRE\n",
    "for token in doc:\n",
    "    #print(token)\n",
    "    #print(token.text, token.pos_, token.dep_)\n",
    "    #print(token.lemma_)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision & Recall \n",
    "def calc_p_r(text_output): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "# Stanza https://stanfordnlp.github.io/stanza/installation_usage.html + Språkbanken https://spraakbanken.gu.se/en/resources/stanzalem\n",
    "# https://nlp.johnsnowlabs.com/2020/05/05/lemma_sv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF/IDF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.121124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.038846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.057190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline  Headings  TF/IDF   NER\n",
       "count  34.000000      34.0    34.0  34.0\n",
       "mean    0.121124       0.0     0.0   0.0\n",
       "std     0.183991       0.0     0.0   0.0\n",
       "min     0.029412       0.0     0.0   0.0\n",
       "25%     0.038846       0.0     0.0   0.0\n",
       "50%     0.057190       0.0     0.0   0.0\n",
       "75%     0.108333       0.0     0.0   0.0\n",
       "max     1.000000       0.0     0.0   0.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 1 --> Baseline\n",
    "for i, score in enumerate(scores['Baseline']) :\n",
    "    scores['Baseline'][i] = 1/((i+1))\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF/IDF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.121124</td>\n",
       "      <td>1.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.183991</td>\n",
       "      <td>1.011520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.038846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.057190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.108333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline   Headings  TF/IDF   NER\n",
       "count  34.000000  34.000000    34.0  34.0\n",
       "mean    0.121124   1.352941     0.0   0.0\n",
       "std     0.183991   1.011520     0.0   0.0\n",
       "min     0.029412   0.000000     0.0   0.0\n",
       "25%     0.038846   1.000000     0.0   0.0\n",
       "50%     0.057190   1.000000     0.0   0.0\n",
       "75%     0.108333   1.000000     0.0   0.0\n",
       "max     1.000000   6.000000     0.0   0.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 2 --> Headings\n",
    "# Sets all 'Headings' scores to 0, mostly for testing so i can run this multiple times, \n",
    "# but also to make sure nothing weird has happened earlier in the code.\n",
    "scores['Headings'] = 0\n",
    "for i, sentence in enumerate(org_sentences):\n",
    "    for word in article.title.split(' '):\n",
    "        if word in sentence:\n",
    "            scores.at[i, 'Headings'] += 1\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score\n",
    "* Diskutera hur vi kan använda måtten \n",
    "* If similarity is close --> Similar content --> Remove redundance?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER \n",
    "* (nltk lib) --> (Meningar med Named Entities är troligtvis viktigare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER.ipynb#scrollTo=9RgiqfX5XDqb\n",
    "# SPARK NLP \n",
    "import sparknlp\n",
    "spark = sparknlp.start(m1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Standardize\n",
    "* standardize all scores\n",
    "### Combine\n",
    "* Combine the scores into one overall score\n",
    "* add weight and/or ML if time allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF/IDF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.848572</td>\n",
       "      <td>4.663223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.090179</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.170715</td>\n",
       "      <td>0.649309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.710982</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435143</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.251250</td>\n",
       "      <td>1.652788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.119898</td>\n",
       "      <td>0.649309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.021384</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.055238</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.166688</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.208482</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.243846</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.274158</td>\n",
       "      <td>-1.357647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.300429</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.323415</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.343697</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.361726</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.377857</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.392375</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.405510</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.417451</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.428354</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.438348</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.447543</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.456030</td>\n",
       "      <td>0.649309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.463889</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.471186</td>\n",
       "      <td>0.649309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.477980</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.484321</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.490253</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.495815</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.501039</td>\n",
       "      <td>1.652788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.505956</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Baseline  Headings  TF/IDF  NER\n",
       "0   4.848572  4.663223     0.0  0.0\n",
       "1   2.090179 -0.354169     0.0  0.0\n",
       "2   1.170715  0.649309     0.0  0.0\n",
       "3   0.710982 -0.354169     0.0  0.0\n",
       "4   0.435143 -0.354169     0.0  0.0\n",
       "5   0.251250  1.652788     0.0  0.0\n",
       "6   0.119898  0.649309     0.0  0.0\n",
       "7   0.021384 -0.354169     0.0  0.0\n",
       "8  -0.055238 -0.354169     0.0  0.0\n",
       "9  -0.116536 -0.354169     0.0  0.0\n",
       "10 -0.166688 -0.354169     0.0  0.0\n",
       "11 -0.208482 -0.354169     0.0  0.0\n",
       "12 -0.243846 -0.354169     0.0  0.0\n",
       "13 -0.274158 -1.357647     0.0  0.0\n",
       "14 -0.300429 -0.354169     0.0  0.0\n",
       "15 -0.323415 -0.354169     0.0  0.0\n",
       "16 -0.343697 -0.354169     0.0  0.0\n",
       "17 -0.361726 -0.354169     0.0  0.0\n",
       "18 -0.377857 -0.354169     0.0  0.0\n",
       "19 -0.392375 -0.354169     0.0  0.0\n",
       "20 -0.405510 -0.354169     0.0  0.0\n",
       "21 -0.417451 -0.354169     0.0  0.0\n",
       "22 -0.428354 -0.354169     0.0  0.0\n",
       "23 -0.438348 -0.354169     0.0  0.0\n",
       "24 -0.447543 -0.354169     0.0  0.0\n",
       "25 -0.456030  0.649309     0.0  0.0\n",
       "26 -0.463889 -0.354169     0.0  0.0\n",
       "27 -0.471186  0.649309     0.0  0.0\n",
       "28 -0.477980 -0.354169     0.0  0.0\n",
       "29 -0.484321 -0.354169     0.0  0.0\n",
       "30 -0.490253 -0.354169     0.0  0.0\n",
       "31 -0.495815 -0.354169     0.0  0.0\n",
       "32 -0.501039  1.652788     0.0  0.0\n",
       "33 -0.505956 -0.354169     0.0  0.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize\n",
    "scores_standardized = StandardScaler.fit_transform(self=StandardScaler(), X=scores)\n",
    "scores_standardized = pd.DataFrame(scores_standardized, columns=columns)\n",
    "scores_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Reassemble according to overall score ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a87a8a1195fdcabb9ca7a50815c6d80bb1ab206e151f4378da93ce8d88425d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
