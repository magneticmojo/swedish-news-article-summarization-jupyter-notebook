{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrapping -->  module för att ladda ner artiklar \n",
    "#import newspaper  \n",
    "from newspaper import Article\n",
    "\n",
    "#text = \"resources/svenska/nyhetstexter/text001.htm\"\n",
    "text = \"https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\"\n",
    "\n",
    "print(text)\n",
    "article = Article(text, language='sv')\n",
    "\n",
    "article.download()\n",
    "article.parse()\n",
    "print(article.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<newspaper.article.Article at 0x143f5bee0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "import newspaper\n",
    "with open(\"resources/svenska/nyhetstexter/text001.htm\", 'rb') as fh:\n",
    "    ht = fh.read()\n",
    "article = newspaper.Article(url = ' ')\n",
    "article.set_html(ht)\n",
    "article.parse()\n",
    "\n",
    "title = article.title\n",
    "body = article.text\n",
    "\n",
    "\n",
    "article\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful soup \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# /Users/afoolonahill/Documents/HT2022/SPRAK/Project/resources/svenska/nyhetstexter/text001.htm\n",
    "#with open(\"resources/svenska/nyhetstexter/text001.htm\".encode('ISO 8859-1')) as fp:\n",
    "#    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "#soup = BeautifulSoup(\"<html>a web page</html>\", 'html.parser')\n",
    "\n",
    "#tag = soup.b\n",
    "\n",
    "txt = open()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering\n",
    "* Hur stor korpus ska vi ha? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "swe_stop_words = stopwords.words('swedish')\n",
    "print(len(swe_stop_words))\n",
    "\n",
    "# Snowball Swedish Stop Words\n",
    "snowball_sw = pd.read_csv(\"resources/stop_words_swedish_snowball .txt\")\n",
    "print(snowball_sw)\n",
    "\n",
    "# Borrowed from https://github.com/peterdalle/svensktext/tree/master/stoppord\n",
    "def get_stopwords(wordlist = \"standard\"):\n",
    "    if wordlist == \"standard\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord.csv\"\n",
    "    elif wordlist == \"many\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-mycket.csv\"\n",
    "    elif wordlist == \"politics\":\n",
    "        url = \"https://raw.githubusercontent.com/peterdalle/svensktext/master/stoppord/stoppord-politik.csv\"\n",
    "    else:\n",
    "        raise ValueError(\"Argument 'wordlist' must be 'standard', 'many' or 'politics', not '{}'.\".format(wordlist))\n",
    "    return pd.read_csv(url, header=1, encoding=\"utf-8\")\n",
    "\n",
    "stopwords = get_stopwords()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Stop Word Filtering On Example (Original Text) \n",
    "def stop_word_filtering(original_text): \n",
    "    swf_text = None\n",
    "    return swf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer & NER \n",
    "\n",
    "* LEmmatizer verkar ok \n",
    "* NER --> helt klart bristande -- men det kan duga? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy NLP Pipeline\n",
    "# spaCy + Lemmy (https://github.com/sorenlind/lemmy) ??? --> Testa om det blir bättre täckning (recall)? \n",
    "import spacy\n",
    "#from spacy.lang.sv.examples import sentences \n",
    "\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "\n",
    "nlp = spacy.load(\"sv_core_news_sm\")\n",
    "\n",
    "doc = nlp(\"Man bör kalla saker och ting vid deras rätta namn och det som pågår idag i Vietnam, det är en form av tortyr. Det man nu gör, det är att plåga människor. Plåga en nation för att förödmjuka den, tvinga den till underkastelse under maktspråk. Och därför är bombningarna ett illdåd. Och av det har vi många exempel i den moderna historien. Och de är i allmänhet förbundna med ett namn: Guernica, Oradour, Babij Jar, Katyń, Lidice, Sharpeville, Treblinka. Där har våldet triumferat. Men eftervärldens dom har fallit hård över dem som burit ansvaret. Nu fogas ett nytt namn till raden: Hanoi, julen 1972.\")\n",
    "#print(doc.text)\n",
    "print(doc.ents) # --> KANSKE ATT DET STORA PAKETET ÄR BÄTTRE\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    #print(token.text, token.pos_, token.dep_)\n",
    "    print(token.lemma_)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision & Recall \n",
    "def calc_p_r(text_output): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "# Stanza https://stanfordnlp.github.io/stanza/installation_usage.html + Språkbanken https://spraakbanken.gu.se/en/resources/stanzalem\n",
    "# https://nlp.johnsnowlabs.com/2020/05/05/lemma_sv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index org text sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 1 --> Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 2 --> Headings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score\n",
    "* Diskutera hur vi kan använda måtten \n",
    "* If similarity is close --> Similar content --> Remove redundance?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER \n",
    "* (nltk lib) --> (Meningar med Named Entities är troligtvis viktigare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER.ipynb#scrollTo=9RgiqfX5XDqb\n",
    "# SPARK NLP \n",
    "import sparknlp\n",
    "spark = sparknlp.start(m1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Standardize and combine scores for each sentence\n",
    "* Reassemble according to ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f84c718007c4e73e911614ffefbbc4d70113307eb785d27a429d66e7eb72440b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
