{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports --> TODO fixa ordning \n",
    "# Web scrapping -->  module för att ladda ner artiklar \n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import nltk \n",
    "import ssl\n",
    "import re  # används ej någonstans (tror jag) / björn\n",
    "import regex as rex # \n",
    "\n",
    "\n",
    "# Summarization length of original text\n",
    "percentage = 0.15\n",
    "n_sentences = 3\n",
    "\n",
    "# Fixes some errors, found online at https://github.com/gunthercox/ChatterBot/issues/930#issuecomment-322111087\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\"\n",
    "#text = 'https://www.svt.se/nyheter/utrikes/stall-dina-fragor-om-kriget-till-svt-s-utrikesreportrar'\n",
    "#text = \"https://www.aftonbladet.se/nyheter/a/kE6j0a/uppgifter-viktigt-fynd-i-jakten-pa-mordarna-i-sodertalje\"\n",
    "text = 'https://www.svt.se/nyheter/utrikes/foi-expert-varnar-for-allvarliga-luckor-i-undervattensbevakningen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(text, language='sv')\n",
    "article.download()\n",
    "article.parse()\n",
    "text = article.text\n",
    "homepage = article.meta_data['al']['ios']['app_name']\n",
    "link = article.url\n",
    "title = article.title\n",
    "\n",
    "# Beroende på vilken hemsida nyheten kommer ifrån kan titeln och texten inehålla delar av sidan man egentligen inte bryr sig om\n",
    "# T.ex. från aftonbladet är titeln med i texten och texten innehåller en mening som: \"publicerad: 30 sep\", man kan ta bort detta men \n",
    "# det blir om vi får tid över.\n",
    "\n",
    "#print('Title:' , article.title, '\\n\\nText: \\n', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Calculate number of sentences to keep\n",
    "\n",
    "### List 1 - sentences\n",
    "* Varje mening separat\n",
    "\n",
    "### Dataframe - scores\n",
    "#### columns are the score of each ranking measure\n",
    "* Baseline\n",
    "* Headings\n",
    "* TF/IDF-score\n",
    "* NER\n",
    "* ~~Class~~ //Om vi har tid för ML\n",
    "\n",
    "### List 2 -> Cleaned for Stop Words \n",
    "* Varje mening separat \n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Sentences List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Säkerhetspolisen konstaterar att det har skett detonationer vid Nord Stream 1 och 2 i svensk ekonomisk zon',\n",
       " 'Det nämns dock inget om antalet sprängningar',\n",
       " '– Att genomföra det här sabotaget pekar på sårbarheten i den här typen av anläggningar och det är ett sätt att utöva påtryckningar i sig: ”Det här är vad vi kan göra mot er!”, säger Niklas Granholm, forskningsledare vid Totalförsvarets forskningsinsitut (FOI)',\n",
       " 'En av fyra ledningar intakt',\n",
       " 'Danska statliga Energistyrelsen uppgav dock på onsdagen att en av Nord Streams fyra rörledningar, Nord Stream 2 Linje B, inte är skadad – trots de kraftiga explosionerna']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes endlines:\n",
    "from token import NEWLINE\n",
    "\n",
    "org_sentences = text.replace('\\n\\n', '. ')\n",
    "# creates some exceptions from above rule\n",
    "org_sentences = org_sentences.replace('.. ', '. ')\n",
    "org_sentences = org_sentences.replace(':. ', ': ')\n",
    "org_sentences = org_sentences.split('. ')\n",
    "\n",
    "sentences_to_remove = []\n",
    "for i, sentence in enumerate(org_sentences): \n",
    "    if sentence == title: \n",
    "        sentences_to_remove.append(sentence)\n",
    "    if 'publicerad:' in sentence.lower(): \n",
    "        sentences_to_remove.append(sentence)\n",
    "\n",
    "org_sentences = [sentence for sentence in org_sentences if sentence not in sentences_to_remove]\n",
    "\n",
    "org_sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Baseline  24 non-null     int64\n",
      " 1   Headings  24 non-null     int64\n",
      " 2   TF        24 non-null     int64\n",
      " 3   NER       24 non-null     int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 896.0 bytes\n"
     ]
    }
   ],
   "source": [
    "index = range(org_sentences.__len__())\n",
    "columns = ['Baseline', 'Headings', 'TF', 'NER']\n",
    "scores = pd.DataFrame(index=index, columns=columns)\n",
    "scores.fillna(0, inplace=True)\n",
    "scores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create spacy doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "# \"lemmatization accuracy 0.95\"\n",
    "# Create spacy nlp object \n",
    "nlp = spacy.load(\"sv_core_news_sm\") # nlp used by lemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['säkerhetspolis konstatera att den ha ske detonation vid Nord stream 1 och 2 i svensk ekonomisk zon ', 'en nämn dock ingen om antal sprängning ', '– att genomföra en här sabotag peka på sårbarhet i en här typ av anläggning och den vara en sätt att utöva påtryckning i sig : ” den här vara vad vi kunna göra mot ni ! ” , säga Nikla Granholm , forskningsledare vid Totalförsvarets forskningsinsitut ( FOI ) ', 'man av fyra ledning intakt ', 'danska statlig Energistyrelsen uppge dock på onsdag att en av Nord Streams fyra rörledning , Nord stream 2 Linje B , inte vara skada – trots en kraftig explosionerna ', '– om en av en fyra gasrör vara intakt , så ge den Ryssland möjlighet att utöva påtryckning mot importör – den vilja säga Västeuropa , säga Nikla Granholm ', 'danska Energistyrelsens twitterkonto foto : Twitter 5 oktober 2022 ', '” påtryckning att öppna ” ', 'en övrig tre rör : Nord stream 1 Linje A och Linje B samt Nord stream 2 Linje A uppge vara obrukbara efter detonationere ', 'Uppgifterna innebära att Nord stream 2 kanske kunna öppna , trots att den på grund av amerikansk sanktion årsskifte 2019/2020 aldrig bli godkända av tysk myndighet ', '– vi ha Nord stream 1 i funktion , medan Nord stream 2 aldrig togs i bruk ', 'den här kunna vara ytterlig en påtryckning med syfte att tvinga Tyskland att öppna Nord stream 2 – en röra i all fall , om den skola visa sig vara intakt , säga Granholm ', 'tre av Nord Streams fyra ledning vara förstörda enligt Danmark Energistyrelse ( markera rött ) ', 'illustrationen markera ej exakt dragning ', 'foto : Grafik SVT ', 'Sensorer fasa ut ', 'under en sen årtiondena ha hav roll förändra med pipeline för olja och ga , telekomkabl på havsbott , havsbaserad vindkraft ', 'Detonationerna illustrera sårbarhet tydlig , säga Granholm ', '– man fasa ut mången av en sensorsystem som vi ha bygga upp på 1980- tale ', 'status på de just nu kunna jag inte säga någon om ', 'en fast bevakningssystem under vatten omgärda dock av hög sekretess ', 'under kalla krig lades linje med undervattensmikrofon ( SOSUS ) ut i del av Östersjön , vilken SVT rapportera ', '– en fast låg för en mycken nära kust och i skärgård , men finnas också ute till hav , säga Nikla Granholm och fortsätta : – även om myndighet skala ned volym och kapacitet på en här system så fortsatte forskning i Sverige och internationell ', 'med 25 år utveckling vara en betydlig mycket avancerad än de vara då . ']\n"
     ]
    }
   ],
   "source": [
    "# den --> det \n",
    "# noterar detta att det är en dålig lemmatiserare --> språkbanken stanza / lemmy / kth...  \n",
    "\n",
    "def lemmatizer(list_of_strings):\n",
    "    lemmatized_sentences = []\n",
    "    lemmatized_sentence = ''\n",
    "    for i in range(len(list_of_strings)): \n",
    "        sentence_to_lemmatize = nlp(list_of_strings[i])\n",
    "        for token in sentence_to_lemmatize:\n",
    "            lemma = token.lemma_\n",
    "            lemmatized_sentence += lemma + ' '  \n",
    "        \n",
    "        lemmatized_sentences.append(lemmatized_sentence)\n",
    "        lemmatized_sentence = '' \n",
    "\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# Created Lemmatized DS\n",
    "lemmatized_org_sentences = lemmatizer(org_sentences)\n",
    "print(lemmatized_org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sverige', 'Energistyrelsen', 'Niklas', 'SOSUS', 'Energistyrelsens', 'Östersjön', 'Grafik', 'Danmarks', 'Nord', 'Foto', 'SVT', 'Västeuropa', 'Streams', 'Tyskland', 'FOI', 'Granholm'}\n"
     ]
    }
   ],
   "source": [
    "# För bättre täckning på NER \n",
    "def proper_nouns(list_of_strings):\n",
    "    proper_nouns = set()\n",
    "    for i in range(len(list_of_strings)): \n",
    "        sentence_to_pos = nlp(list_of_strings[i])\n",
    "        for token in sentence_to_pos: \n",
    "            token_str = token.text\n",
    "            if token.pos_ == \"PROPN\" and len(token_str) > 1:\n",
    "                proper_nouns.add(token_str.strip())\n",
    "    return proper_nouns\n",
    "\n",
    "print(proper_nouns(org_sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_recognition(list_of_strings):\n",
    "    doc = nlp(' '.join(list_of_strings))\n",
    "    # Convert tuple[Span] to str\n",
    "    named_entities = doc.ents.__str__()\n",
    "    # Remove string parenthesis \n",
    "    named_entities = named_entities[1:len(named_entities) - 1]\n",
    "    # Create list of strings\n",
    "    named_entities = named_entities.split(',')\n",
    "    \n",
    "    named_entities_set = set()\n",
    "    for entity in named_entities: \n",
    "        named_entities_set.add(entity.strip())\n",
    "    return named_entities_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def get_swe_stop_words(): \n",
    "    swe_stop_words = set(stopwords.words('swedish'))\n",
    "    # Not stop word cleaning \n",
    "    swe_stop_words.update([',', '\"', ':', '-', '–', '”'])\n",
    "    return swe_stop_words\n",
    "\n",
    "def stop_word_filtering(list_of_strings):\n",
    "    word_tokens = word_tokenize(' '.join(list_of_strings))\n",
    "    filtered_sentence_into_singletons = [w for w in word_tokens if not w.lower() in get_swe_stop_words()]\n",
    "    return filtered_sentence_into_singletons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_distribution(list): \n",
    "    fdist = FreqDist(word.lower() for word in word_tokenize(' '.join(list)))\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = stop_word_filtering(lemmatized_org_sentences) \n",
    "fdist = frequency_distribution(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.054825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline  Headings    TF   NER\n",
       "count  24.000000      24.0  24.0  24.0\n",
       "mean    0.157332       0.0   0.0   0.0\n",
       "std     0.209559       0.0   0.0   0.0\n",
       "min     0.041667       0.0   0.0   0.0\n",
       "25%     0.054825       0.0   0.0   0.0\n",
       "50%     0.080128       0.0   0.0   0.0\n",
       "75%     0.148810       0.0   0.0   0.0\n",
       "max     1.000000       0.0   0.0   0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 1 --> Baseline\n",
    "for i, score in enumerate(scores['Baseline']) :\n",
    "    scores['Baseline'][i] = 1/((i+1))\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.157332</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209559</td>\n",
       "      <td>0.481543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.054825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.148810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline   Headings    TF   NER\n",
       "count  24.000000  24.000000  24.0  24.0\n",
       "mean    0.157332   1.166667   0.0   0.0\n",
       "std     0.209559   0.481543   0.0   0.0\n",
       "min     0.041667   0.000000   0.0   0.0\n",
       "25%     0.054825   1.000000   0.0   0.0\n",
       "50%     0.080128   1.000000   0.0   0.0\n",
       "75%     0.148810   1.000000   0.0   0.0\n",
       "max     1.000000   2.000000   0.0   0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 2 --> Headings\n",
    "# Sets all 'Headings' scores to 0, mostly for testing so i can run this multiple times, \n",
    "# but also to make sure nothing weird has happened earlier in the code.\n",
    "scores['Headings'] = 0\n",
    "for i, sentence in enumerate(org_sentences): # Lemmatizerad? \n",
    "    for word in article.title.split(' '):\n",
    "        if word in sentence:\n",
    "            scores.at[i, 'Headings'] += 1\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sverigedemokraterna få ordförandepost i riksdag justitie och utrikesutskott \n",
    "[' få ', 'ordförandepost ', 'riksdag ', 'utrikesutskott ']\n",
    "\n",
    "* bara ord i lemma \n",
    "* ord i lemma med efter letters\n",
    "* ord i lemma med före letters --> x\n",
    "* före + lemma + efter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209559</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.054825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline   Headings    TF   NER\n",
       "count  24.000000  24.000000  24.0  24.0\n",
       "mean    0.157332   0.041667   0.0   0.0\n",
       "std     0.209559   0.204124   0.0   0.0\n",
       "min     0.041667   0.000000   0.0   0.0\n",
       "25%     0.054825   0.000000   0.0   0.0\n",
       "50%     0.080128   0.000000   0.0   0.0\n",
       "75%     0.148810   0.000000   0.0   0.0\n",
       "max     1.000000   1.000000   0.0   0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_title = stop_word_filtering(lemmatizer(title.split(' ')))\n",
    "p = rex.compile(r\"\\b\\S*\\L<words>\\S*\\b | \\b\\L<words>\\b | \\b\\L<words>\\S*\\b\", re.IGNORECASE, words=preprocessed_title)\n",
    "p.findall\n",
    "\n",
    "for i, sentence in enumerate(lemmatized_org_sentences):    \n",
    "    #print(sentence)\n",
    "    matches = p.findall(sentence)\n",
    "    #print(matches)\n",
    "    scores.at[i, \"Headings\"] = len(matches)\n",
    "\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TERM FREQUENCY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "#Term Frequency\n",
    "def termfreq(sentence, word):\n",
    "    N = len(sentence)\n",
    "    occurance = len([token for token in sentence if token == word])\n",
    "    return occurance/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "#Inverse Document Frequency\n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = fdist.get(word) + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(len(lemmatized_org_sentences)/word_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "# TF*IDF-score \n",
    "def tf_idf(sentence):\n",
    "    score = 0\n",
    "    #tf_idf_vec = np.zeros((len(filtered_words),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "         \n",
    "        score += tf*idf\n",
    "        #tf_idf_vec[index_dict[word]] = value \n",
    "    return score\n",
    "\n",
    "for i, sentence in enumerate(lemmatized_org_sentences):\n",
    "    scores.at[i, 'TF'] = tf_idf(sentence)\n",
    "\n",
    "#scores.describe()\n",
    "#scores['TF'].idxmax()\n",
    "#scores.loc[scores['TF'] == scores['TF'].median()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Niklas Granholm', 'Sverige', 'Energistyrelsen', 'Östersjön', 'Danska statliga Energistyrelsen', 'SOSUS', 'Energistyrelsens', 'Nord Streams', 'Grafik', 'Nord', 'Västeuropa', 'Grafik SVT Sensorer', 'Tyskland', 'Danska Energistyrelsens', 'Granholm', 'Niklas', 'Stream 2', 'Totalförsvarets', 'Linje B samt Nord', 'Danmarks', 'Foto', 'Danmarks Energistyrelse', 'SVT', 'Streams', 'Ryssland', 'FOI'}\n"
     ]
    }
   ],
   "source": [
    "scores['NER'] = 0\n",
    "named_entities = named_entity_recognition(org_sentences)\n",
    "proper_nouns = proper_nouns(org_sentences)\n",
    "ner_unique = named_entities.union(proper_nouns)\n",
    "print(ner_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>25.215988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.821866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>57.927523</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.176898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>37.478216</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Baseline  Headings         TF  NER\n",
       "0  1.000000         0  25.215988    1\n",
       "1  0.500000         0  13.821866    0\n",
       "2  0.333333         0  57.927523    3\n",
       "3  0.250000         0   8.176898    0\n",
       "4  0.200000         0  37.478216    4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = rex.compile(r\"\\L<words>\", words=ner_unique)\n",
    "\n",
    "for i, sentence in enumerate(org_sentences):\n",
    "    matches = p.findall(sentence)\n",
    "    scores.at[i, \"NER\"] = len(matches)\n",
    "\n",
    "scores.describe()\n",
    "scores.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.161452</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.046203</td>\n",
       "      <td>-0.346410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.505535</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.200388</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.286896</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.754145</td>\n",
       "      <td>1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677576</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.322557</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311984</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.311582</td>\n",
       "      <td>1.732051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.068257</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.216061</td>\n",
       "      <td>1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.105835</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.161226</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.236403</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.323294</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.337956</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.173746</td>\n",
       "      <td>1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.419199</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.211173</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.485670</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.058995</td>\n",
       "      <td>1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.541063</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.393233</td>\n",
       "      <td>1.732051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.587934</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.628109</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.287550</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.662927</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.370925</td>\n",
       "      <td>1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.693393</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.379694</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.720275</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.067970</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.744169</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.235817</td>\n",
       "      <td>-0.346410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.765549</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.082867</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.784791</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.160481</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.802200</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.154600</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.818026</td>\n",
       "      <td>11.989579</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>1.039230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.832477</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>0.666387</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.845723</td>\n",
       "      <td>-0.521286</td>\n",
       "      <td>-0.111385</td>\n",
       "      <td>-1.039230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Baseline   Headings        TF       NER\n",
       "0   6.161452  -0.521286  0.046203 -0.346410\n",
       "1   2.505535  -0.521286 -0.200388 -1.039230\n",
       "2   1.286896  -0.521286  0.754145  1.039230\n",
       "3   0.677576  -0.521286 -0.322557 -1.039230\n",
       "4   0.311984  -0.521286  0.311582  1.732051\n",
       "5   0.068257  -0.521286  0.216061  1.039230\n",
       "6  -0.105835  -0.521286 -0.161226  0.346410\n",
       "7  -0.236403  -0.521286 -0.323294 -1.039230\n",
       "8  -0.337956  -0.521286  0.173746  1.039230\n",
       "9  -0.419199  -0.521286  0.211173  0.346410\n",
       "10 -0.485670  -0.521286 -0.058995  1.039230\n",
       "11 -0.541063  -0.521286  0.393233  1.732051\n",
       "12 -0.587934  -0.521286 -0.000285  0.346410\n",
       "13 -0.628109  -0.521286 -0.287550 -1.039230\n",
       "14 -0.662927  -0.521286 -0.370925  1.039230\n",
       "15 -0.693393  -0.521286 -0.379694 -1.039230\n",
       "16 -0.720275  -0.521286  0.067970 -1.039230\n",
       "17 -0.744169  -0.521286 -0.235817 -0.346410\n",
       "18 -0.765549  -0.521286 -0.082867 -1.039230\n",
       "19 -0.784791  -0.521286 -0.160481 -1.039230\n",
       "20 -0.802200  -0.521286 -0.154600 -1.039230\n",
       "21 -0.818026  11.989579  0.009564  1.039230\n",
       "22 -0.832477  -0.521286  0.666387  0.346410\n",
       "23 -0.845723  -0.521286 -0.111385 -1.039230"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize\n",
    "scores_standardized = StandardScaler.fit_transform(self=StandardScaler(), X=scores)\n",
    "scores_standardized = pd.DataFrame(scores_standardized, columns=columns)\n",
    "scores_standardized['Baseline'] *= 1.5\n",
    "scores_standardized['Headings'] *= 2.5\n",
    "scores_standardized['TF'] *= 0.3\n",
    "scores_standardized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Summarization Length (number of sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarization:  4 \n",
      "original:  24\n"
     ]
    }
   ],
   "source": [
    "num_of_org_sentences = len(org_sentences)\n",
    "summarization_num_sentences = round(num_of_org_sentences * percentage)\n",
    "\n",
    "print(\"summarization: \", summarization_num_sentences, \"\\noriginal: \", num_of_org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine\n",
    "* Combine the scores into one overall score\n",
    "* add weight and/or ML if time allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21  0  2  4]\n",
      "Säkerhetspolisen konstaterar att det har skett detonationer vid Nord Stream 1 och 2 i svensk ekonomisk zon\n"
     ]
    }
   ],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  \n",
    "\n",
    "#final_score = scores_standardized.drop('TF', axis=1).sum(axis=1)\n",
    "final_score = scores_standardized.sum(axis=1)\n",
    "best_sentences = final_score.nlargest(summarization_num_sentences, keep='all').index.values\n",
    "print(best_sentences)\n",
    "\n",
    "print(org_sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity heurstic \n",
    "# Rubrik --> Hur mycket lika --> Ta bort redundans \n",
    "# 5 fem väldigt lika --> heuristik välja bort något av det     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Reassemble according to overall score ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage:\n",
      "\n",
      "FOI-expert varnar för bristande spaning i Östersjön \n",
      "\n",
      "Under kalla kriget lades linjer med undervattensmikrofoner (SOSUS) ut i delar av Östersjön, vilket SVT rapporterat\n",
      "Säkerhetspolisen konstaterar att det har skett detonationer vid Nord Stream 1 och 2 i svensk ekonomisk zon\n",
      "– Att genomföra det här sabotaget pekar på sårbarheten i den här typen av anläggningar och det är ett sätt att utöva påtryckningar i sig: ”Det här är vad vi kan göra mot er!”, säger Niklas Granholm, forskningsledare vid Totalförsvarets forskningsinsitut (FOI)\n",
      "Danska statliga Energistyrelsen uppgav dock på onsdagen att en av Nord Streams fyra rörledningar, Nord Stream 2 Linje B, inte är skadad – trots de kraftiga explosionerna\n",
      "\n",
      "\n",
      "\n",
      "N sentences:\n",
      "\n",
      "Under kalla kriget lades linjer med undervattensmikrofoner (SOSUS) ut i delar av Östersjön, vilket SVT rapporterat\n",
      "Säkerhetspolisen konstaterar att det har skett detonationer vid Nord Stream 1 och 2 i svensk ekonomisk zon\n",
      "– Att genomföra det här sabotaget pekar på sårbarheten i den här typen av anläggningar och det är ett sätt att utöva påtryckningar i sig: ”Det här är vad vi kan göra mot er!”, säger Niklas Granholm, forskningsledare vid Totalförsvarets forskningsinsitut (FOI)\n"
     ]
    }
   ],
   "source": [
    "# Percentage length of original text --> summarization \n",
    "print(\"Percentage:\\n\")\n",
    "print(title, \"\\n\")\n",
    "for i in best_sentences: \n",
    "    print(org_sentences[i])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# N sentences \n",
    "print(\"N sentences:\\n\")\n",
    "for i in best_sentences[0:n_sentences]: \n",
    "    print(org_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Newspaper3k: \n",
      " Säkerhetspolisen konstaterar att det har skett detonationer vid Nord Stream 1 och 2 i svensk ekonomisk zon.\n",
      "En av fyra ledningar intaktDanska statliga Energistyrelsen uppgav dock på onsdagen att en av Nord Streams fyra rörledningar, Nord Stream 2 Linje B, inte är skadad – trots de kraftiga explosionerna.\n",
      "Danska Energistyrelsens twitterkonto Foto: Twitter 5 oktober 2022”Påtryckning att öppna”De övriga tre rören: Nord Stream 1 Linje A och Linje B samt Nord Stream 2 Linje A uppges vara obrukbara efter detonationerna.\n",
      "Uppgifterna innebär att Nord Stream 2 kanske kan öppnas, trots att den på grund av amerikanska sanktioner årsskiftet 2019/2020 aldrig blev godkänd av tyska myndigheter.\n",
      "– Vi hade Nord Stream 1 i funktion, medan Nord Stream 2 aldrig togs i bruk.\n"
     ]
    }
   ],
   "source": [
    "# Newspaper Summarization\n",
    "article.nlp()\n",
    "print(\"\\nNewspaper3k: \\n\", article.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization = link + '\\n\\n' + 'Title: ' + '\\n' + title + '\\n\\n' + 'Summarization:' + '\\n'\n",
    "for sentence in best_sentences: \n",
    "    summarization += org_sentences[sentence] + '\\n'\n",
    "summarization += '\\n\\n' + 'Newspaper3k:' + '\\n' + 'Title: ' + '\\n' + title + \"\\n\\n\" + article.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "FILEPATH = f'./summarizations/{homepage}/'\n",
    "filename = f\"{FILEPATH}{title}.txt\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "     f.write(summarization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f84c718007c4e73e911614ffefbbc4d70113307eb785d27a429d66e7eb72440b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
