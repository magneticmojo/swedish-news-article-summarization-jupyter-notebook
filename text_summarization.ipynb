{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktionsbaserad textsammanfattare med olika rankningsmått "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports --> TODO fixa ordning \n",
    "# Web scrapping -->  module för att ladda ner artiklar \n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import nltk \n",
    "import ssl\n",
    "import re  # används ej någonstans (tror jag) / björn\n",
    "import regex as rex # \n",
    "\n",
    "\n",
    "# Summarization length of original text\n",
    "percentage = 0.15\n",
    "n_sentences = 3\n",
    "\n",
    "# Fixes some errors, found online at https://github.com/gunthercox/ChatterBot/issues/930#issuecomment-322111087\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lägg till nya artiklar \n",
    "\n",
    "* Hämta komplett url \n",
    "* Lägg till i python cellen under här\n",
    "* Tilldela till variabeln text \n",
    "* Tryck Restart och sen Run All \n",
    "* Filerna hamnar i mappen \"summarizations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"https://www.aftonbladet.se/nyheter/a/kE6ExL/sd-far-tunga-poster-i-utskotten\"\n",
    "#text = 'https://www.svt.se/nyheter/utrikes/stall-dina-fragor-om-kriget-till-svt-s-utrikesreportrar'\n",
    "#text = \"https://www.aftonbladet.se/nyheter/a/kE6j0a/uppgifter-viktigt-fynd-i-jakten-pa-mordarna-i-sodertalje\"\n",
    "#text = 'https://www.aftonbladet.se/nyheter/a/EQaJRo/blixtbygget-ska-radda-tyskland-i-vinter'\n",
    "#text = 'https://www.aftonbladet.se/nyheter/a/3EEJGX/trump-vantas-kallas-att-vittna-om-6-januari'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LÄnkar för Utvärdering Projekt --> Ran with percentage 0.3 & 0.15 for evaluation material \n",
    "#text = 'https://www.aftonbladet.se/nyheter/a/EamE65/mannen-misstanks-ha-mordat-nancy-38--havdar-blackout'\n",
    "#text = 'https://www.aftonbladet.se/nyheter/a/y66vWA/polisen-tackar-nej-till-hund-som-kunde-lost-mordet-pa-helena-andersson'\n",
    "#text = 'https://www.aftonbladet.se/nojesbladet/melodifestivalen/a/wOJA0A/melodifestivalen-2022-appen-kraschar'\n",
    "#text = 'https://www.svt.se/nyheter/inrikes/l-kd-och-m-ska-inga-i-regeringen-sd-far-stort-inflytande'\n",
    "#text = 'https://www.svt.se/nyheter/inrikes/nord-stream-lackan-kan-ha-varit-medveten-attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(text, language='sv')\n",
    "article.download()\n",
    "article.parse()\n",
    "text = article.text\n",
    "homepage = article.meta_data['al']['ios']['app_name']\n",
    "link = article.url\n",
    "title = article.title\n",
    "\n",
    "# Beroende på vilken hemsida nyheten kommer ifrån kan titeln och texten inehålla delar av sidan man egentligen inte bryr sig om\n",
    "# T.ex. från aftonbladet är titeln med i texten och texten innehåller en mening som: \"publicerad: 30 sep\", man kan ta bort detta men \n",
    "# det blir om vi får tid över.\n",
    "\n",
    "#print('Title:' , article.title, '\\n\\nText: \\n', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Calculate number of sentences to keep\n",
    "\n",
    "### List 1 - sentences\n",
    "* Varje mening separat\n",
    "\n",
    "### Dataframe - scores\n",
    "#### columns are the score of each ranking measure\n",
    "* Baseline\n",
    "* Headings\n",
    "* TF/IDF-score\n",
    "* NER\n",
    "* ~~Class~~ //Om vi har tid för ML\n",
    "\n",
    "### List 2 -> Cleaned for Stop Words \n",
    "* Varje mening separat \n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Sentences List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott',\n",
       " 'Nu går ledarna för vänsterblocket till hård attack',\n",
       " '– Det är skrämmande, ganska chockartat, säger Socialdemokraternas gruppledare Lena Hallengren till Aftonbladet',\n",
       " 'Sverigedemokraterna , Moderaterna, Kristdemokraterna och Liberalerna har delat upp posterna i utskotten och EU-nämnden',\n",
       " 'Där tar Sverigedemokraterna flera viktiga poster']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes endlines:\n",
    "from token import NEWLINE\n",
    "\n",
    "org_sentences = text.replace('\\n\\n', '. ')\n",
    "# creates some exceptions from above rule\n",
    "org_sentences = org_sentences.replace('.. ', '. ')\n",
    "org_sentences = org_sentences.replace(':. ', ': ')\n",
    "org_sentences = org_sentences.split('. ')\n",
    "\n",
    "# Detta borde egentligen tillhöra stopwordlistan\n",
    "sentences_to_remove = []\n",
    "for i, sentence in enumerate(org_sentences): \n",
    "    if sentence == title: \n",
    "        sentences_to_remove.append(sentence)\n",
    "    if 'publicerad:' in sentence.lower(): \n",
    "        sentences_to_remove.append(sentence)\n",
    "    if 'uppdaterad:' in sentence.lower(): \n",
    "        sentences_to_remove.append(sentence)\n",
    "\n",
    "org_sentences = [sentence for sentence in org_sentences if sentence not in sentences_to_remove]\n",
    "\n",
    "org_sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Baseline  32 non-null     int64\n",
      " 1   Headings  32 non-null     int64\n",
      " 2   TF        32 non-null     int64\n",
      " 3   NER       32 non-null     int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 1.1 KB\n"
     ]
    }
   ],
   "source": [
    "index = range(org_sentences.__len__())\n",
    "columns = ['Baseline', 'Headings', 'TF', 'NER']\n",
    "scores = pd.DataFrame(index=index, columns=columns)\n",
    "scores.fillna(0, inplace=True)\n",
    "scores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create spacy doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Credit to Explosion for sv_core_news_sm --> https://github.com/explosion \n",
    "# \"lemmatization accuracy 0.95\"\n",
    "# Create spacy nlp object \n",
    "nlp = spacy.load(\"sv_core_news_sm\") # nlp used by lemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sverigedemokraterna få ordförandepost i riksdag justitie och utrikesutskott ', 'nu gå ledarna för vänsterblock till hård attack ', '– den vara skrämmande , ganska chockarta , säga Socialdemokraterna gruppledare Lena Hallengren till Aftonbladet ', 'Sverigedemokraterna , Moderat , Kristdemokraterna och Liberalerna ha dela upp post i utskott och EU-nämnden ', 'där ta Sverigedemokraterna flera viktig post ', 'bland annan tilldela parti ordförandepost i arbetsmarknadsutskott , näringsutskott , justitieutskott samt utrikesutskottet , enligt en pressmeddelande ', 'de erhåller även post som vice ordförande i civilutskott , trafikutskott , försvarsutskotte samt skatteutskotte ', '– den som överraska jag mycket , men som jag kunna se varför de vilja ha , vara ordförandepost i utrikesutskott ', 'den vara en tecken på att de lycka i förhandling med M och KD , säga Aftonbladet My Rohwedder i Aftonbladet tv ', '” få liten inflytande ” ', 'Nomineringarna väcka reaktion inom vänsterblock ', '– den vara skrämmande , ganska chockarta ', 'Utrikesutskottet vara inte vilken som gärna , den skola representera Sverige riksdag utomlands och överhuvudtag i relation till omvärld , så den vara en viktig position ', 'och här ha Moderat sålt sig ', 'den vara tyvärr en tecken på vart vi vara på väg , att för Ulf Kristersson del vara den viktig att få makt och inflytande , man sälja sig billig , säga Lena Hallengren , gruppledare för Socialdemokrater och fortsätta : – Utrikesutskottet vara otrolig betydelsefull med en omvärld som vara lite säga orolig ', 'att i en läge peka ut en sverigedemokrat , en parti med rött i nazism , som den som skola företräd svensk folk i riksdag utrikes . ', 'på samma sätt som jag nog vara lite skaka av denna vara den nog ingenting mot vad mången av en land som ge vi säkerhetsgaranti vara , som undra vart Sverige vara på väg ', '” Skämmer ut Sverige internationell ” ', 'flera politisk ledare protestera mot beslut på social medi ', 'Miljöpartiets språkröra Märta stenevi skriva på twitter : ” så en högerextrem parti som inte kunna välja mellan Putin och bid skola leda utrikesutskott och försvarsutskotte ', 'Finnas ju ingen som kunna kunna gå fel i denna ” ', 'V-ledar Nooshie Dadgostar instämma : ” Återigen skämma en icke-tillträdd regering ut Sverige internationell ', 'en här gång genom att ge Sverigedemokraterna ordförandepost i utrikesutskotte ” , skriva hon på twitter ', 'Vänsterpartiets riksdagsledamot ali Esbati lyfta också SD-ledamöterna Martin kinnun och Marku Wiechel besök i Syrien 2017 där de mötte Assad-regim ', '” för utrikesutskott anta jag att den stå mellan Marcus Wiechel och Martin Kinnunen , här bägge på delegationsresa på egen initiativ och mot UD : s avråda , till Syrien 2017 ” , skriva han på twitter ', 'även Centerpartiets avgående partiledare Annie Lööf gå till attack efter beslut : ” så M , KD och L ge SD i uppdrag att leda utrikes- och försvarspolitik i riksdag ', 'i denna känslig säkerhetspolitisk läge , när Sverige skola bli medlem i Nato och vara ordförande i EU ', 'den vara olycklig och komma påverka Sverige anseende i värld ” ', '” få liten inflytande ” ', 'Utrikespolitiska institutets direktör Jakob Hallgren tro dock inte att utskotte komma att ha någon stor inverkan på en svensk utrikespolitik ', '– den här vara en oerhöra viktig post som kanske vara mycket representativ än annan utskottspost , men man måste komma ihåg att inom utrikespolitik ha vi en regering , en utrikesminister och en försvarsminist som ha mycket mycket verkställande makt , säga han och tillägga : – fråga vara hur stor inflytande ordförandefrågorna få om riksdagsparti förhandla fram överenskommelsa i förväg ', 'då komma utskotten att få liten inflytande , säga han . ']\n"
     ]
    }
   ],
   "source": [
    "# den --> det \n",
    "# noterar detta att det är en dålig lemmatiserare --> språkbanken stanza / lemmy / kth...  \n",
    "\n",
    "def lemmatizer(list_of_strings):\n",
    "    lemmatized_sentences = []\n",
    "    lemmatized_sentence = ''\n",
    "    for i in range(len(list_of_strings)): \n",
    "        sentence_to_lemmatize = nlp(list_of_strings[i])\n",
    "        for token in sentence_to_lemmatize:\n",
    "            lemma = token.lemma_\n",
    "            lemmatized_sentence += lemma + ' '  \n",
    "        \n",
    "        lemmatized_sentences.append(lemmatized_sentence)\n",
    "        lemmatized_sentence = '' \n",
    "\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# Created Lemmatized DS\n",
    "lemmatized_org_sentences = lemmatizer(org_sentences)\n",
    "print(lemmatized_org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Kristerssons', 'SD', 'Wiechels', 'Martin', 'Aftonbladet', 'Socialdemokraternas', 'Biden', 'EU', 'Sveriges', 'Putin', 'Nato', 'Annie', 'Markus', 'Kinnunen', 'Lena', 'KD', 'Esbati', 'UD', 'Sverige', 'Jakob', 'Stenevi', 'Wiechel', 'Rohwedder', 'Hallengren', 'Socialdemokraterna', 'Syrien', 'Hallgren'}\n"
     ]
    }
   ],
   "source": [
    "# För bättre täckning på NER \n",
    "def proper_nouns(list_of_strings):\n",
    "    proper_nouns = set()\n",
    "    for i in range(len(list_of_strings)): \n",
    "        sentence_to_pos = nlp(list_of_strings[i])\n",
    "        for token in sentence_to_pos: \n",
    "            token_str = token.text\n",
    "            if token.pos_ == \"PROPN\" and len(token_str) > 1:\n",
    "                proper_nouns.add(token_str.strip())\n",
    "    return proper_nouns\n",
    "\n",
    "print(proper_nouns(org_sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_recognition(list_of_strings):\n",
    "    doc = nlp(' '.join(list_of_strings))\n",
    "    # Convert tuple[Span] to str\n",
    "    named_entities = doc.ents.__str__()\n",
    "    # Remove string parenthesis \n",
    "    named_entities = named_entities[1:len(named_entities) - 1]\n",
    "    # Create list of strings\n",
    "    named_entities = named_entities.split(',')\n",
    "    \n",
    "    named_entities_set = set()\n",
    "    for entity in named_entities: \n",
    "        named_entities_set.add(entity.strip())\n",
    "    return named_entities_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def get_swe_stop_words(): \n",
    "    swe_stop_words = set(stopwords.words('swedish'))\n",
    "    # Not stop word cleaning \n",
    "    swe_stop_words.update([',', '\"', ':', '-', '–', '”'])\n",
    "    return swe_stop_words\n",
    "\n",
    "def stop_word_filtering(list_of_strings):\n",
    "    word_tokens = word_tokenize(' '.join(list_of_strings))\n",
    "    filtered_sentence_into_singletons = [w for w in word_tokens if not w.lower() in get_swe_stop_words()]\n",
    "    return filtered_sentence_into_singletons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_distribution(list): \n",
    "    fdist = FreqDist(word.lower() for word in word_tokenize(' '.join(list)))\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = stop_word_filtering(lemmatized_org_sentences) \n",
    "fdist = frequency_distribution(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "(1/N --> n=ordning mening kommer i dvs. första meningen får N=1 -> 1/1, andra meningen får N=2 -> 1/2, osv.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.126828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.188323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline  Headings    TF   NER\n",
       "count  32.000000      32.0  32.0  32.0\n",
       "mean    0.126828       0.0   0.0   0.0\n",
       "std     0.188323       0.0   0.0   0.0\n",
       "min     0.031250       0.0   0.0   0.0\n",
       "25%     0.041250       0.0   0.0   0.0\n",
       "50%     0.060662       0.0   0.0   0.0\n",
       "75%     0.114583       0.0   0.0   0.0\n",
       "max     1.000000       0.0   0.0   0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 1 --> Baseline\n",
    "for i, score in enumerate(scores['Baseline']) :\n",
    "    scores['Baseline'][i] = 1/((i+1))\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.126828</td>\n",
       "      <td>1.218750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.188323</td>\n",
       "      <td>0.608243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.041250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.060662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline   Headings    TF   NER\n",
       "count  32.000000  32.000000  32.0  32.0\n",
       "mean    0.126828   1.218750   0.0   0.0\n",
       "std     0.188323   0.608243   0.0   0.0\n",
       "min     0.031250   0.000000   0.0   0.0\n",
       "25%     0.041250   1.000000   0.0   0.0\n",
       "50%     0.060662   1.000000   0.0   0.0\n",
       "75%     0.114583   1.000000   0.0   0.0\n",
       "max     1.000000   3.000000   0.0   0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking metric 2 --> Headings\n",
    "# Sets all 'Headings' scores to 0, mostly for testing so i can run this multiple times, \n",
    "# but also to make sure nothing weird has happened earlier in the code.\n",
    "scores['Headings'] = 0\n",
    "for i, sentence in enumerate(org_sentences): # Lemmatizerad? \n",
    "    for word in article.title.split(' '):\n",
    "        if word in sentence:\n",
    "            scores.at[i, 'Headings'] += 1\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sverigedemokraterna få ordförandepost i riksdag justitie och utrikesutskott \n",
    "[' få ', 'ordförandepost ', 'riksdag ', 'utrikesutskott ']\n",
    "\n",
    "* bara ord i lemma \n",
    "* ord i lemma med efter letters\n",
    "* ord i lemma med före letters --> x\n",
    "* före + lemma + efter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.126828</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.188323</td>\n",
       "      <td>1.490562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.060662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.114583</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Baseline   Headings    TF   NER\n",
       "count  32.000000  32.000000  32.0  32.0\n",
       "mean    0.126828   1.312500   0.0   0.0\n",
       "std     0.188323   1.490562   0.0   0.0\n",
       "min     0.031250   0.000000   0.0   0.0\n",
       "25%     0.041250   0.000000   0.0   0.0\n",
       "50%     0.060662   1.000000   0.0   0.0\n",
       "75%     0.114583   2.000000   0.0   0.0\n",
       "max     1.000000   5.000000   0.0   0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_title = stop_word_filtering(lemmatizer(title.split(' ')))\n",
    "p = rex.compile(r\"\\b\\S*\\L<words>\\S*\\b | \\b\\L<words>\\b | \\b\\L<words>\\S*\\b\", re.IGNORECASE, words=preprocessed_title)\n",
    "p.findall\n",
    "\n",
    "for i, sentence in enumerate(lemmatized_org_sentences):    \n",
    "    #print(sentence)\n",
    "    matches = p.findall(sentence)\n",
    "    #print(matches)\n",
    "    scores.at[i, \"Headings\"] = len(matches)\n",
    "\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TERM FREQUENCY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "#Term Frequency\n",
    "def termfreq(sentence, word):\n",
    "    N = len(sentence)\n",
    "    occurance = len([token for token in sentence if token == word])\n",
    "    return occurance/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "#Inverse Document Frequency\n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = fdist.get(word) + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(len(lemmatized_org_sentences)/word_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed https://www.askpython.com/python/examples/tf-idf-model-from-scratch (with adjustments)\n",
    "# TF*IDF-score \n",
    "def tf_idf(sentence):\n",
    "    score = 0\n",
    "    #tf_idf_vec = np.zeros((len(filtered_words),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "         \n",
    "        score += tf*idf\n",
    "        #tf_idf_vec[index_dict[word]] = value \n",
    "    return score\n",
    "\n",
    "for i, sentence in enumerate(lemmatized_org_sentences):\n",
    "    scores.at[i, 'TF'] = tf_idf(sentence)\n",
    "\n",
    "#scores.describe()\n",
    "#scores['TF'].idxmax()\n",
    "#scores.loc[scores['TF'] == scores['TF'].median()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF*IDF-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking metric 3 --> TF*IDF\n",
    "\n",
    "# Term Weights --> Calculate importance of single words in text/doc\n",
    "# Binary term weights --> document specific\n",
    "# TF*IDF term weights --> document-collection specific \n",
    "\n",
    "# Assign weights to each dimension (attr/word) of each sentence (record/example) \n",
    "\n",
    "# Term Frequency (TF-score) --> TFij == frequency of the jth term in in the ith doc \n",
    "\n",
    "# Inverse Document Frequency \n",
    "# idf-score of the jth term measures the uniqueness of the jth term in the collection of documents\n",
    "# IDFj = log(M / Nj)\n",
    "#\n",
    "# M = total num of docs in collection \n",
    "# Nj is the number of documents that contain the jth term\n",
    "\n",
    "# HIGH TF*IDF-score \n",
    "# Word frequent in document && Occur in few documents of the collection \n",
    "# LOW TF*IDF-score\n",
    "# Not present in document || present in all documents of the collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Martin Kinnunen', 'Kristerssons', 'SD', 'Wiechels', 'Martin', 'Moderaterna', 'Marcus Wiechel', 'Markus Wiechels', 'UD:s', 'Aftonbladet', 'Socialdemokraternas', 'Biden', 'EU', 'Sveriges', 'Putin', 'Nato', 'Twitter', 'Annie', 'Skämmer', 'Markus', 'Kinnunen', 'Lena', 'Jakob Hallgren', 'KD', 'Esbati', 'UD', 'Sverige', 'Lena Hallengren', 'Miljöpartiets', 'Jakob', 'Ulf Kristerssons', 'Ali', 'Stenevi', 'Wiechel', 'Märta', 'Rohwedder', 'Aftonbladets My Rohwedder', 'Hallengren', 'Socialdemokraterna', 'Syrien', 'Hallgren'}\n"
     ]
    }
   ],
   "source": [
    "scores['NER'] = 0\n",
    "named_entities = named_entity_recognition(org_sentences)\n",
    "proper_nouns = proper_nouns(org_sentences)\n",
    "ner_unique = named_entities.union(proper_nouns)\n",
    "print(ner_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>17.542233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.884586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>26.721661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>24.534428</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>11.882315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Baseline  Headings         TF  NER\n",
       "0  1.000000         4  17.542233    1\n",
       "1  0.500000         0  11.884586    0\n",
       "2  0.333333         0  26.721661    3\n",
       "3  0.250000         2  24.534428    3\n",
       "4  0.200000         1  11.882315    1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = rex.compile(r\"\\L<words>\", words=ner_unique)\n",
    "\n",
    "for i, sentence in enumerate(org_sentences):\n",
    "    matches = p.findall(sentence)\n",
    "    scores.at[i, \"NER\"] = len(matches)\n",
    "\n",
    "scores.describe()\n",
    "scores.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Headings</th>\n",
       "      <th>TF</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.066120</td>\n",
       "      <td>4.579654</td>\n",
       "      <td>-0.181553</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.019884</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.275455</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.671139</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.029198</td>\n",
       "      <td>0.875140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996766</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>-0.065501</td>\n",
       "      <td>0.875140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592143</td>\n",
       "      <td>-0.532518</td>\n",
       "      <td>-0.275493</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.322393</td>\n",
       "      <td>6.283711</td>\n",
       "      <td>0.159330</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.129716</td>\n",
       "      <td>6.283711</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.014793</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.127188</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.875140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.217105</td>\n",
       "      <td>-0.532518</td>\n",
       "      <td>-0.326027</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.290673</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.273380</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.351979</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.260954</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.403854</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.197186</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.448318</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.322740</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.486854</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.743527</td>\n",
       "      <td>0.875140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.520572</td>\n",
       "      <td>-0.532518</td>\n",
       "      <td>0.150270</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.550324</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>0.393143</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.576770</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.294190</td>\n",
       "      <td>0.303620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.600432</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.206028</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.621728</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.179702</td>\n",
       "      <td>2.589699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.640996</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.139686</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.658512</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.066469</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.674505</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>-0.033807</td>\n",
       "      <td>0.303620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.689165</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>2.589699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.702653</td>\n",
       "      <td>-0.532518</td>\n",
       "      <td>0.347194</td>\n",
       "      <td>2.018179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.715103</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>0.188446</td>\n",
       "      <td>0.875140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.726631</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.062986</td>\n",
       "      <td>0.875140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.737335</td>\n",
       "      <td>-2.236575</td>\n",
       "      <td>-0.200864</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.747301</td>\n",
       "      <td>-0.532518</td>\n",
       "      <td>-0.326027</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.756603</td>\n",
       "      <td>-0.532518</td>\n",
       "      <td>0.145077</td>\n",
       "      <td>-0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.765304</td>\n",
       "      <td>4.579654</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.773462</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>-0.196586</td>\n",
       "      <td>-0.839420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Baseline  Headings        TF       NER\n",
       "0   7.066120  4.579654 -0.181553 -0.267900\n",
       "1   3.019884 -2.236575 -0.275455 -0.839420\n",
       "2   1.671139 -2.236575 -0.029198  0.875140\n",
       "3   0.996766  1.171539 -0.065501  0.875140\n",
       "4   0.592143 -0.532518 -0.275493 -0.267900\n",
       "5   0.322393  6.283711  0.159330 -0.839420\n",
       "6   0.129716  6.283711  0.009519 -0.839420\n",
       "7  -0.014793  1.171539  0.008490 -0.839420\n",
       "8  -0.127188 -2.236575  0.013009  0.875140\n",
       "9  -0.217105 -0.532518 -0.326027 -0.839420\n",
       "10 -0.290673 -2.236575 -0.273380 -0.839420\n",
       "11 -0.351979 -2.236575 -0.260954 -0.839420\n",
       "12 -0.403854  1.171539  0.197186 -0.267900\n",
       "13 -0.448318 -2.236575 -0.322740 -0.267900\n",
       "14 -0.486854  1.171539  0.743527  0.875140\n",
       "15 -0.520572 -0.532518  0.150270 -0.839420\n",
       "16 -0.550324 -2.236575  0.393143 -0.267900\n",
       "17 -0.576770 -2.236575 -0.294190  0.303620\n",
       "18 -0.600432 -2.236575 -0.206028 -0.839420\n",
       "19 -0.621728  1.171539  0.179702  2.589699\n",
       "20 -0.640996 -2.236575 -0.139686 -0.839420\n",
       "21 -0.658512 -2.236575 -0.066469 -0.267900\n",
       "22 -0.674505  1.171539 -0.033807  0.303620\n",
       "23 -0.689165  1.171539  0.007320  2.589699\n",
       "24 -0.702653 -0.532518  0.347194  2.018179\n",
       "25 -0.715103  1.171539  0.188446  0.875140\n",
       "26 -0.726631 -2.236575 -0.062986  0.875140\n",
       "27 -0.737335 -2.236575 -0.200864 -0.267900\n",
       "28 -0.747301 -0.532518 -0.326027 -0.839420\n",
       "29 -0.756603 -0.532518  0.145077 -0.267900\n",
       "30 -0.765304  4.579654  0.994731 -0.839420\n",
       "31 -0.773462  1.171539 -0.196586 -0.839420"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize\n",
    "scores_standardized = StandardScaler.fit_transform(self=StandardScaler(), X=scores)\n",
    "scores_standardized = pd.DataFrame(scores_standardized, columns=columns)\n",
    "scores_standardized['Baseline'] *= 1.5\n",
    "scores_standardized['Headings'] *= 2.5\n",
    "scores_standardized['TF'] *= 0.3\n",
    "scores_standardized\n",
    "\n",
    "# ÄNDRA COL NAME TF col --> TF*IDF TODO \n",
    "# COUNTER WEIGHT: \n",
    "# IF -->  \n",
    "# Baseline score low (e.g. below median)\n",
    "# && term_frequency high (note: not TF*IDF) (e.g. above upper quartile)\n",
    "# && NER high (e.g. above upper quartile)\n",
    "# THEN: \n",
    "# add_counterweight(sentence, counter_weight) \n",
    "# counter_weight:  \n",
    "# final rankposition = i -->  ∑ -1 (-1 may be too big weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Summarization Length (number of sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarization:  5 \n",
      "original:  32\n"
     ]
    }
   ],
   "source": [
    "num_of_org_sentences = len(org_sentences)\n",
    "summarization_num_sentences = round(num_of_org_sentences * percentage)\n",
    "\n",
    "print(\"summarization: \", summarization_num_sentences, \"\\noriginal: \", num_of_org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine\n",
    "* Combine the scores into one overall score\n",
    "* add weight and/or ML if time allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5  6 30 19]\n",
      "Sverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott\n"
     ]
    }
   ],
   "source": [
    "# Combination Function\n",
    "# Här ligger ML om vi gör det  \n",
    "\n",
    "#final_score = scores_standardized.drop('TF', axis=1).sum(axis=1)\n",
    "final_score = scores_standardized.sum(axis=1)\n",
    "best_sentences = final_score.nlargest(summarization_num_sentences, keep='all').index.values\n",
    "print(best_sentences)\n",
    "\n",
    "print(org_sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity heurstic \n",
    "# Rubrik --> Hur mycket lika --> Ta bort redundans \n",
    "# 5 fem väldigt lika --> heuristik välja bort något av det     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble output \n",
    "* Reassemble according to overall score ranking\n",
    "* Output summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage:\n",
      "\n",
      "SD får tunga poster i utskotten \n",
      "\n",
      "Sverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott\n",
      "Bland annat tilldelas partiet ordförandeposten i arbetsmarknadsutskottet, näringsutskottet, justitieutskottet samt utrikesutskottet, enligt ett pressmeddelande\n",
      "De erhåller även posten som vice ordförande i civilutskottet, trafikutskottet, försvarsutskottet samt skatteutskottet\n",
      "– Det här är en oerhört viktig post som kanske är mer representativ än andra utskottsposter, men man måste komma ihåg att inom utrikespolitiken har vi en regering, en utrikesminister och en försvarsminister som har mycket mer verkställande makt, säger han och tillägger: – Frågan är hur stort inflytande ordförandefrågorna får om riksdagspartierna förhandlar fram överenskommelser i förväg\n",
      "Miljöpartiets språkrör Märta Stenevi skriver på Twitter: ”Så ett högerextremt parti som inte kunnat välja mellan Putin och Biden ska leda utrikesutskottet och försvarsutskottet\n",
      "\n",
      "\n",
      "\n",
      "N sentences:\n",
      "\n",
      "Sverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott\n",
      "Bland annat tilldelas partiet ordförandeposten i arbetsmarknadsutskottet, näringsutskottet, justitieutskottet samt utrikesutskottet, enligt ett pressmeddelande\n",
      "De erhåller även posten som vice ordförande i civilutskottet, trafikutskottet, försvarsutskottet samt skatteutskottet\n"
     ]
    }
   ],
   "source": [
    "# Percentage length of original text --> summarization \n",
    "print(\"Percentage:\\n\")\n",
    "print(title, \"\\n\")\n",
    "for i in best_sentences: \n",
    "    print(org_sentences[i])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# N sentences \n",
    "print(\"N sentences:\\n\")\n",
    "for i in best_sentences[0:n_sentences]: \n",
    "    print(org_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Newspaper3k: \n",
      " SD får tunga poster i utskottenPublicerad: 30 september Uppdaterad: 30 septemberSverigedemokraterna får ordförandeposten i riksdagens justitie- och utrikesutskott.\n",
      "Utrikesutskottet är inte vilket som helst, det ska representera Sveriges riksdag utomlands och överhuvudtaget i relationen till omvärlden, så det är en viktig position.\n",
      "Den här gången genom att ge Sverigedemokraterna ordförandeposten i utrikesutskottet”, skriver hon på Twitter.\n",
      "I detta känsliga säkerhetspolitiska läge, när Sverige ska bli medlem i Nato och vara ordförande i EU.\n",
      "”Får mindre inflytande”Utrikespolitiska institutets direktör Jakob Hallgren tror dock inte att utskottet kommer att ha någon större inverkan på den svenska utrikespolitiken.\n"
     ]
    }
   ],
   "source": [
    "# Newspaper Summarization\n",
    "article.nlp()\n",
    "print(\"\\nNewspaper3k: \\n\", article.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization = link + '\\n\\n' + 'Title: ' + '\\n' + title + '\\n\\n' + 'Compression ratio: ' + str(len(best_sentences)/len(org_sentences)) + '\\n\\n' + 'Summarization:' + '\\n'\n",
    "for sentence in best_sentences: \n",
    "    summarization += org_sentences[sentence] + '\\n'\n",
    "summarization += '\\n\\n' + 'Newspaper3k:' + '\\n' + 'Title: ' + '\\n' + title + \"\\n\\n\" + article.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "FILEPATH = f'./summarizations/{homepage}/'\n",
    "filename = f\"{FILEPATH}{title}.txt\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "     f.write(summarization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f84c718007c4e73e911614ffefbbc4d70113307eb785d27a429d66e7eb72440b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
